{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTTH08: Regularized Neural Net\n",
    "\n",
    "TODO: Ghi họ tên và MSSV của bạn (vd, Nguyễn Văn A - 1234567)\n",
    "\n",
    "---\n",
    "\n",
    "Nguyễn Phan Mạnh Hùng - 1312727\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cách làm bài và nộp bài\n",
    "\n",
    "**Làm bài**\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này; trong file, mình đã để từ `TODO` để cho biết những chỗ mà bạn cần phải làm (trong đó, `TODO` đầu tiên là bạn phải ghi họ tên và MSSV vào phần đầu của file). Trong khi làm bài, thường xuyên `Ctrl + S` để lưu lại bài làm của bạn, tránh mất mát thông tin.\n",
    "\n",
    "*Lưu ý: tuyệt đối không gian lận. Nếu vi phạm thì bạn sẽ bị 0 điểm cho cả phần thực hành môn học. Nên nhớ mục tiêu chính ở đây là học kiến thức.*\n",
    "\n",
    "**Nộp bài**\n",
    "\n",
    "Khi chấm bài, đầu tiên mình sẽ chọn `Cell` - `Run All` để chạy tất cả các cell trong notebook của bạn; do đó, trước khi nộp bài, bạn nên chạy thử `Cell` - `Run All` để đảm bảo mọi chuyện diễn ra đúng như mong đợi.\n",
    "\n",
    "Sau đó, trong thư mục `MSSV` (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`) bạn đặt file `Ex08-RegularizedNeuralNet.ipynb` (không cần nộp file dữ liệu `mnist.pkl.gz`); rồi nén thư mục `MSSV` này lại và nộp ở link trên moodle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle\n",
    "import gzip\n",
    "# You can also import other things ...\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hàm đọc dữ liệu\n",
    "\n",
    "Trong bài này, bạn sẽ thử nghiệm Neural Net trên bộ dữ liệu MNIST (file `mnist.pkl.gz` đính kèm). Đây là bộ dữ liệu gồm các ảnh chữ số viết tay từ 0-9 (10 lớp); mỗi ảnh có kích thước $28\\times 28$ và là ảnh grayscale. Bộ dữ liệu đã được chia sẵn làm 3 tập: tập huấn luyện gồm 50000 ảnh, tập validation gồm 10000 ảnh, và tập kiểm tra gồm 10000 ảnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_mnist(mnist_file):\n",
    "    \"\"\"\n",
    "    Reads MNIST data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mnist_file : string\n",
    "        The name of the MNIST file (e.g., 'mnist.plk.gz').\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (X_train, Y_train, X_val, Y_val, X_test, Y_test) : tuple\n",
    "        X_train : numpy array, shape (N=50000, d+1=785)\n",
    "            Input vectors of the training set.\n",
    "        Y_train: numpy array, shape (N=50000)\n",
    "            Outputs of the training set.\n",
    "        X_val : numpy array, shape (N=10000, d+1=785)\n",
    "            Input vectors of the validation set.\n",
    "        Y_val: numpy array, shape (N=10000)\n",
    "            Outputs of the validation set.\n",
    "        X_test : numpy array, shape (N=10000, d+1=785)\n",
    "            Input vectors of the test set.\n",
    "        Y_test: numpy array, shape (N=10000)\n",
    "            Outputs of the test set.\n",
    "    \"\"\"\n",
    "    f = gzip.open(mnist_file, 'rb')\n",
    "    train_data, val_data, test_data = cPickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    X_train, Y_train = train_data\n",
    "    X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
    "    \n",
    "    X_val, Y_val = val_data\n",
    "    X_val = np.hstack((np.ones((X_val.shape[0], 1)), X_val))\n",
    "    \n",
    "    X_test, Y_test = test_data\n",
    "    X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hàm lan truyền tiến qua Neural Net\n",
    "\n",
    "Trong bài này, ta sẽ sử dụng nơ-ron sigmoid ở các tẩng ẩn, và tầng softmax là tầng xuất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Computes sigmoid function for each element of numpy array Z.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def softmax(Z):\n",
    "    \"\"\"\n",
    "    Computes softmax function for each row of numpy array Z.\n",
    "    \"\"\"\n",
    "    A = np.exp(Z)\n",
    "    A /= np.sum(A, axis=1, keepdims=True)\n",
    "    return A\n",
    "\n",
    "def forward_prop(X, Ws):\n",
    "    \"\"\"\n",
    "    Forward propagates X through layers of neural nets to get the final outputs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (N, d+1)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones (corresponding to x_0).\n",
    "    Ws : list of numpy arrays\n",
    "        The list of each layer's W; W of layer l will have the shape of (d^(l-1)+1, d^(l)) where \n",
    "        d^(l-1) is the number of neurons (not count the +1 neuron) of layer l-1, and \n",
    "        d^(l) is the number of neurons (not count the +1 neuron) of layer l.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A : numpy array, shape (N, K=10)\n",
    "        The maxtrix of Neural Net's output vectors; each row is an output vector (containing each \n",
    "        class's probability given the corresponding input vector).\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    A = X;\n",
    "    for i in range(len(Ws)):\n",
    "        W = Ws[i];\n",
    "        Z = A.dot(W)\n",
    "        if i == len(Ws)-1:\n",
    "            A = softmax(Z);\n",
    "        else:\n",
    "            A = sigmoid(Z);\n",
    "            A = np.hstack((np.ones((A.shape[0],1)),A));\n",
    "    return A;\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hàm huấn luyện Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addOne(A):\n",
    "    return np.hstack((np.ones((A.shape[0],1)),A));\n",
    "def meanBinaryError(X, W, Y):\n",
    "    #for debugging: def forward_prop(X, Ws):\n",
    "    A = forward_prop(X, W);\n",
    "    myY = np.nonzero(np.max(A, axis = 1, keepdims = True) == A)[1]\n",
    "    error = 1 - np.sum(myY == Y) * 1.0 / Y.shape[0]\n",
    "    return error\n",
    "def train_neural_net(X_train, Y_train, X_val, Y_val, layer_sizes, learning_rate, mnb_size, max_patience, \n",
    "                     l2_reg_level):\n",
    "    \"\"\"\n",
    "    Trains Neural Net on the dataset (X_train, Y_train).\n",
    "    Cost function: Mean Negative Log Likelihood + L2 regularization.\n",
    "    Optimization algorithm: Stochastic Gradient Descent (SGD) with early stopping.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : numpy array, shape (N, d + 1)\n",
    "        The matrix of input vectors (each row corresponds to an input vector) of the training set; \n",
    "        the first column of this matrix is all ones (corresponding to x_0).\n",
    "    Y_train : numpy array, shape (N,)\n",
    "        The vector of outputs of the training set.\n",
    "    X_val : numpy array, shape (N_val, d + 1)\n",
    "        The matrix of input vectors (each row corresponds to an input vector) of the validation set; \n",
    "        the first column of this matrix is all ones (corresponding to x_0).\n",
    "    Y_val : numpy array, shape (N_val,)\n",
    "        The vector of outputs of the validation set.  \n",
    "    layer_sizes : list of ints\n",
    "        The list of each layer' size (not count the +1 neurons).\n",
    "        E.g. layer_sizes = [784, 30, 10] means: the 1st layer (input layer) has 784 neurons,\n",
    "        the 2nd layer (hidden layer) has 30 neurons, the 3rd layer (output layer) has 10 neurons.\n",
    "    learning_rate : float\n",
    "        Learning rate of SGD.\n",
    "    mnb_size : int\n",
    "        Minibatch size of SGD.\n",
    "    max_patience : int\n",
    "        The parameter of early stopping. You'll have a `patience` variable with initial value equal to\n",
    "        `max_patience`. During the training, you'll keep track of the best MBE (Mean Binary Error) \n",
    "        on the validation set; if the MBE on the validation set at the current epoch < the current \n",
    "        best one, you'll reset `patience` to `max_patience`; otherwise, `patience` -= 1. \n",
    "        When `patience` = 0, you'll terminate SGD.\n",
    "    l2_reg_level : float\n",
    "        The level (the coefficient) of L2 regularization.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (best_Ws, train_errs, val_errs) : tuple\n",
    "        best_Ws : list of numpy arrays\n",
    "            The list of each layer's W; W of layer l will have the shape of (d^(l-1)+1, d^(l)) where \n",
    "            d^(l-1) is the number of neurons (not count the +1 neuron) of layer l-1, and \n",
    "            d^(l) is the number of neurons (not count the +1 neuron) of layer l.\n",
    "            It's the parameters having smallest MBE on the validation set.\n",
    "        train_errs: list of floats\n",
    "            List of MBEs on the training set after each epoch.\n",
    "        val_errs: list of floats\n",
    "            List of MBEs on the validation set after each epoch.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    After each epoch, you need to print out: \n",
    "    - The MBE on the training set and validation set.\n",
    "    - The value of `patience`.\n",
    "    E.g., 'Epoch ..., training err ..., val err ..., patience ...'.\n",
    "    \n",
    "    After the training, you need to print out:\n",
    "    - The best MBE on the validation set.\n",
    "    - The corresponding epoch.\n",
    "    - The corresponding MBE on the training set.\n",
    "    E.g., \"Best val err ..., at epoch ..., corresponding train err ...\".\n",
    "    \"\"\"\n",
    "    # Init weights\n",
    "    np.random.seed(0) # Note: this will fix the randomization so that we'll get the same random numbers each run; \n",
    "                      # it make comparisons (e.g. between different values of `l2_reg_level`) more accurate. \n",
    "    Ws = [np.random.randn(layer_sizes[l]+1, layer_sizes[l+1]) / np.sqrt(layer_sizes[l]+1) for l in range(len(layer_sizes)-1)]\n",
    "    \n",
    "    # TODO\n",
    "    bestMBEval = 111; #infinity ~ > 1\n",
    "    corEpoch = -1;\n",
    "    corMBEtrain = 111;\n",
    "    train_errs = [];\n",
    "    val_errs = [];\n",
    "    bestWs = [];\n",
    "    \n",
    "    N = X_train.shape[0];\n",
    "    one_hot_Y = np.eye(layer_sizes[-1]);\n",
    "    rand_idxs = range(N);\n",
    "    max_epoch = 1000000000; #infinity \n",
    "    epoch = -1;\n",
    "    while epoch < max_epoch: #we can also use \"While True:\". However, we should use this condition instead to control when the loop terminates. \n",
    "        epoch += 1\n",
    "        np.random.shuffle(rand_idxs);\n",
    "        for start_idx in range(0,N, mnb_size):\n",
    "            mnb_X = X_train[rand_idxs[start_idx:start_idx+mnb_size]];\n",
    "            mnb_Y = one_hot_Y[Y_train[rand_idxs[start_idx:start_idx+mnb_size]]];\n",
    "            #forward propagation\n",
    "            As = [mnb_X];\n",
    "            #Zs =[];\n",
    "            A = mnb_X;\n",
    "            for i in range(len(Ws)):\n",
    "                W = Ws[i];\n",
    "                Z = A.dot(W)\n",
    "                if i == len(Ws)-1:\n",
    "                    A = softmax(Z);\n",
    "                else:\n",
    "                    A = sigmoid(Z);\n",
    "                    A = np.hstack((np.ones((A.shape[0],1)),A));\n",
    "                    \n",
    "                #Zs.append(Z); #for debuging\n",
    "                As.append(A);\n",
    "            #backward propagation\n",
    "            delta = As[-1] - mnb_Y;\n",
    "            grad = As[-2].T.dot(delta)*1.0/mnb_size + 2.0*l2_reg_level*Ws[-1]; #/mnb_size\n",
    "            Ws[-1] -= learning_rate*grad;\n",
    "            \n",
    "            for it in range(2, len(layer_sizes)):\n",
    "                #print delta.shape, Ws[-it+1].shape, it\n",
    "                \n",
    "                delta = delta.dot(Ws[-it+1].T)*As[-it]*(1-As[-it])\n",
    "                grad = (As[-it-1].T.dot(delta)*1.0/mnb_size)[:,1:] + 2.0*l2_reg_level*Ws[-it]; #/mnb_size\n",
    "                #grad = grad[:,1:] + 1.0*l2_reg_level*Ws[-it];\n",
    "                #if it == 2 and epoch == 0:\n",
    "                    #print (grad[:,1:]).shape, (Ws[-2]).shape\n",
    "                Ws[-it] -= learning_rate*grad;\n",
    "                delta = delta[:,1:];\n",
    "        \n",
    "        eTrain = meanBinaryError(X_train, Ws, Y_train);\n",
    "        eVal = meanBinaryError(X_val, Ws, Y_val);\n",
    "        train_errs.append(eTrain);\n",
    "        val_errs.append(eVal);\n",
    "        \n",
    "        if (eVal < bestMBEval):\n",
    "            bestMBEval = eVal;\n",
    "            corMBEtrain = eTrain;\n",
    "            corEpoch = epoch\n",
    "            patience = max_patience\n",
    "            bestWs = copy.deepcopy(Ws);\n",
    "        else:\n",
    "            patience = patience - 1;        \n",
    "        print 'Epoch ', epoch, ', training err ', eTrain*100, '%, val err ', eVal*100, '%, patience ', patience, '\\n'\n",
    "        if patience == 0:\n",
    "            break;\n",
    "            \n",
    "       \n",
    "    print 'Best val err ', bestMBEval*100, '% at epoch ', corEpoch, ' corresponding train err ',corMBEtrain*100, '%';\n",
    "    return (bestWs,train_errs,val_errs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Thí nghiệm\n",
    "\n",
    "Để thấy được ảnh hưởng của hệ số `l2_reg_level`, bạn sẽ dùng các hàm đã định nghĩa ở trên như sau:\n",
    "\n",
    "1. Đọc dữ liệu.\n",
    "2. Huấn luyện Neural Net trên tập huấn luyện với `layer_sizes = [784, 30, 10]`, `learning_rate = 0.1`, `mnb_size = 10`, `max_patience = 20`, và `l2_reg_level = 0, 0.0001, 0.001`. Để dễ nhìn khi chương trình `print` ra, bạn nên dùng 3 code cell cho 3 lần gọi hàm huấn luyện (ứng với 3 giá trị của `l2_reg_level`).\n",
    "3. Ở cell kế tiếp, bạn sẽ vẽ ra đồ trị có trục hoàng là số lượng epoch và trục tung là độ lỗi. Với mỗi giá trị của `l2_reg_level`, bạn sẽ vẽ ra 2 đường ứng với độ lỗi MBE trên tập huấn luyện và tập validation; như vậy, trên đồ thị sẽ có tất cả 6 đường.\n",
    "4. Cho nhận xét dựa vào đồ thị kết quả.\n",
    "5. Cuối cùng, bạn sẽ tính và in ra độ lỗi trên tập kiểm tra của mô hình có độ lỗi nhỏ nhất trên tập validation (trong số 3 mô hình ứng với 3 giá trị của `l2_reg_level`).\n",
    "\n",
    "(Kết quả chạy của mình: với `l2_reg_level = 0`, độ lỗi trên tập huấn luyện và tập validation lần lượt là 1.076% và 3.480%; với `l2_reg_level = 0.0001`, độ lỗi là 2.114% và 2.910%; với `l2_reg_level = 0.001`, độ lỗi là 6.940% và 6.130%.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = read_mnist('mnist.pkl.gz');\n",
    "l2_reg = [0, 0.0001, 0.001];\n",
    "bestWs = [];\n",
    "train_errs = [];\n",
    "val_errs = [];\n",
    "#def train_neural_net(X_train, Y_train, X_val, Y_val, layer_sizes, learning_rate, mnb_size, max_patience, l2_reg_level):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 , training err  70.88 %, val err  71.19 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  71.626 %, val err  72.02 %, patience  19 \n",
      "\n",
      "Epoch  2 , training err  69.412 %, val err  70.31 %, patience  20 \n",
      "\n",
      "Epoch  3 , training err  70.444 %, val err  70.92 %, patience  19 \n",
      "\n",
      "Epoch  4 , training err  73.884 %, val err  73.73 %, patience  18 \n",
      "\n",
      "Epoch  5 , training err  70.552 %, val err  71.3 %, patience  17 \n",
      "\n",
      "Epoch  6 , training err  68.748 %, val err  68.82 %, patience  20 \n",
      "\n",
      "Epoch  7 , training err  71.282 %, val err  71.89 %, patience  19 \n",
      "\n",
      "Epoch  8 , training err  68.748 %, val err  68.89 %, patience  18 \n",
      "\n",
      "Epoch  9 , training err  71.39 %, val err  71.46 %, patience  17 \n",
      "\n",
      "Epoch  10 , training err  69.06 %, val err  68.93 %, patience  16 \n",
      "\n",
      "Epoch  11 , training err  69.848 %, val err  70.51 %, patience  15 \n",
      "\n",
      "Epoch  12 , training err  68.778 %, val err  68.46 %, patience  20 \n",
      "\n",
      "Epoch  13 , training err  67.63 %, val err  67.34 %, patience  20 \n",
      "\n",
      "Epoch  14 , training err  68.682 %, val err  68.1 %, patience  19 \n",
      "\n",
      "Epoch  15 , training err  69.994 %, val err  69.1 %, patience  18 \n",
      "\n",
      "Epoch  16 , training err  70.53 %, val err  71.55 %, patience  17 \n",
      "\n",
      "Epoch  17 , training err  68.642 %, val err  68.33 %, patience  16 \n",
      "\n",
      "Epoch  18 , training err  67.216 %, val err  66.91 %, patience  20 \n",
      "\n",
      "Epoch  19 , training err  70.812 %, val err  70.34 %, patience  19 \n",
      "\n",
      "Epoch  20 , training err  70.01 %, val err  70.07 %, patience  18 \n",
      "\n",
      "Epoch  21 , training err  66.752 %, val err  67.67 %, patience  17 \n",
      "\n",
      "Epoch  22 , training err  67.344 %, val err  66.44 %, patience  20 \n",
      "\n",
      "Epoch  23 , training err  66.852 %, val err  66.67 %, patience  19 \n",
      "\n",
      "Epoch  24 , training err  66.928 %, val err  66.79 %, patience  18 \n",
      "\n",
      "Epoch  25 , training err  69.802 %, val err  69.98 %, patience  17 \n",
      "\n",
      "Epoch  26 , training err  66.19 %, val err  66.12 %, patience  20 \n",
      "\n",
      "Epoch  27 , training err  69.548 %, val err  70.11 %, patience  19 \n",
      "\n",
      "Epoch  28 , training err  67.078 %, val err  67.58 %, patience  18 \n",
      "\n",
      "Epoch  29 , training err  67.986 %, val err  68.6 %, patience  17 \n",
      "\n",
      "Epoch  30 , training err  68.268 %, val err  68.09 %, patience  16 \n",
      "\n",
      "Epoch  31 , training err  67.238 %, val err  67.42 %, patience  15 \n",
      "\n",
      "Epoch  32 , training err  67.216 %, val err  67.52 %, patience  14 \n",
      "\n",
      "Epoch  33 , training err  66.772 %, val err  66.63 %, patience  13 \n",
      "\n",
      "Epoch  34 , training err  67.724 %, val err  68.04 %, patience  12 \n",
      "\n",
      "Epoch  35 , training err  69.354 %, val err  69.84 %, patience  11 \n",
      "\n",
      "Epoch  36 , training err  71.966 %, val err  71.85 %, patience  10 \n",
      "\n",
      "Epoch  37 , training err  66.162 %, val err  66.82 %, patience  9 \n",
      "\n",
      "Epoch  38 , training err  69.906 %, val err  70.41 %, patience  8 \n",
      "\n",
      "Epoch  39 , training err  67.482 %, val err  68.39 %, patience  7 \n",
      "\n",
      "Epoch  40 , training err  67.558 %, val err  68.54 %, patience  6 \n",
      "\n",
      "Epoch  41 , training err  67.424 %, val err  67.24 %, patience  5 \n",
      "\n",
      "Epoch  42 , training err  66.436 %, val err  65.93 %, patience  20 \n",
      "\n",
      "Epoch  43 , training err  67.854 %, val err  67.32 %, patience  19 \n",
      "\n",
      "Epoch  44 , training err  71.57 %, val err  70.57 %, patience  18 \n",
      "\n",
      "Epoch  45 , training err  65.958 %, val err  66.12 %, patience  17 \n",
      "\n",
      "Epoch  46 , training err  65.006 %, val err  64.23 %, patience  20 \n",
      "\n",
      "Epoch  47 , training err  66.92 %, val err  68.08 %, patience  19 \n",
      "\n",
      "Epoch  48 , training err  66.884 %, val err  67.03 %, patience  18 \n",
      "\n",
      "Epoch  49 , training err  65.35 %, val err  65.52 %, patience  17 \n",
      "\n",
      "Epoch  50 , training err  67.856 %, val err  69.06 %, patience  16 \n",
      "\n",
      "Epoch  51 , training err  68.168 %, val err  67.31 %, patience  15 \n",
      "\n",
      "Epoch  52 , training err  68.226 %, val err  67.59 %, patience  14 \n",
      "\n",
      "Epoch  53 , training err  68.268 %, val err  67.81 %, patience  13 \n",
      "\n",
      "Epoch  54 , training err  67.22 %, val err  66.67 %, patience  12 \n",
      "\n",
      "Epoch  55 , training err  66.452 %, val err  65.95 %, patience  11 \n",
      "\n",
      "Epoch  56 , training err  69.268 %, val err  68.95 %, patience  10 \n",
      "\n",
      "Epoch  57 , training err  68.044 %, val err  67.8 %, patience  9 \n",
      "\n",
      "Epoch  58 , training err  66.716 %, val err  66.5 %, patience  8 \n",
      "\n",
      "Epoch  59 , training err  70.096 %, val err  71.1 %, patience  7 \n",
      "\n",
      "Epoch  60 , training err  67.43 %, val err  67.2 %, patience  6 \n",
      "\n",
      "Epoch  61 , training err  66.834 %, val err  67.87 %, patience  5 \n",
      "\n",
      "Epoch  62 , training err  68.046 %, val err  69.07 %, patience  4 \n",
      "\n",
      "Epoch  63 , training err  68.832 %, val err  69.21 %, patience  3 \n",
      "\n",
      "Epoch  64 , training err  68.258 %, val err  68.4 %, patience  2 \n",
      "\n",
      "Epoch  65 , training err  66.924 %, val err  66.86 %, patience  1 \n",
      "\n",
      "Epoch  66 , training err  66.95 %, val err  65.64 %, patience  0 \n",
      "\n",
      "Best val err  64.23 % at epoch  46  corresponding train err  65.006 %\n",
      "Epoch  0 , training err  54.49 %, val err  54.4 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  49.57 %, val err  49.16 %, patience  20 \n",
      "\n",
      "Epoch  2 , training err  49.55 %, val err  48.66 %, patience  20 \n",
      "\n",
      "Epoch  3 , training err  51.698 %, val err  51.42 %, patience  19 \n",
      "\n",
      "Epoch  4 , training err  53.372 %, val err  52.78 %, patience  18 \n",
      "\n",
      "Epoch  5 , training err  49.186 %, val err  48.55 %, patience  20 \n",
      "\n",
      "Epoch  6 , training err  49.908 %, val err  49.1 %, patience  19 \n",
      "\n",
      "Epoch  7 , training err  50.108 %, val err  49.85 %, patience  18 \n",
      "\n",
      "Epoch  8 , training err  51.042 %, val err  50.25 %, patience  17 \n",
      "\n",
      "Epoch  9 , training err  53.09 %, val err  52.47 %, patience  16 \n",
      "\n",
      "Epoch  10 , training err  51.012 %, val err  50.43 %, patience  15 \n",
      "\n",
      "Epoch  11 , training err  53.626 %, val err  53.04 %, patience  14 \n",
      "\n",
      "Epoch  12 , training err  47.802 %, val err  47.61 %, patience  20 \n",
      "\n",
      "Epoch  13 , training err  48.038 %, val err  47.65 %, patience  19 \n",
      "\n",
      "Epoch  14 , training err  49.496 %, val err  48.52 %, patience  18 \n",
      "\n",
      "Epoch  15 , training err  48.96 %, val err  48.48 %, patience  17 \n",
      "\n",
      "Epoch  16 , training err  47.24 %, val err  46.36 %, patience  20 \n",
      "\n",
      "Epoch  17 , training err  42.936 %, val err  42.33 %, patience  20 \n",
      "\n",
      "Epoch  18 , training err  44.308 %, val err  43.72 %, patience  19 \n",
      "\n",
      "Epoch  19 , training err  47.986 %, val err  46.96 %, patience  18 \n",
      "\n",
      "Epoch  20 , training err  41.758 %, val err  41.16 %, patience  20 \n",
      "\n",
      "Epoch  21 , training err  43.27 %, val err  42.14 %, patience  19 \n",
      "\n",
      "Epoch  22 , training err  47.706 %, val err  47.74 %, patience  18 \n",
      "\n",
      "Epoch  23 , training err  40.21 %, val err  39.22 %, patience  20 \n",
      "\n",
      "Epoch  24 , training err  38.982 %, val err  38.07 %, patience  20 \n",
      "\n",
      "Epoch  25 , training err  41.998 %, val err  40.29 %, patience  19 \n",
      "\n",
      "Epoch  26 , training err  37.988 %, val err  37.05 %, patience  20 \n",
      "\n",
      "Epoch  27 , training err  38.312 %, val err  37.03 %, patience  20 \n",
      "\n",
      "Epoch  28 , training err  38.956 %, val err  38.1 %, patience  19 \n",
      "\n",
      "Epoch  29 , training err  37.076 %, val err  36.03 %, patience  20 \n",
      "\n",
      "Epoch  30 , training err  43.41 %, val err  42.29 %, patience  19 \n",
      "\n",
      "Epoch  31 , training err  38.604 %, val err  37.48 %, patience  18 \n",
      "\n",
      "Epoch  32 , training err  39.562 %, val err  38.95 %, patience  17 \n",
      "\n",
      "Epoch  33 , training err  39.592 %, val err  38.83 %, patience  16 \n",
      "\n",
      "Epoch  34 , training err  37.554 %, val err  36.68 %, patience  15 \n",
      "\n",
      "Epoch  35 , training err  39.122 %, val err  37.78 %, patience  14 \n",
      "\n",
      "Epoch  36 , training err  36.844 %, val err  36.14 %, patience  13 \n",
      "\n",
      "Epoch  37 , training err  41.46 %, val err  41.15 %, patience  12 \n",
      "\n",
      "Epoch  38 , training err  37.432 %, val err  36.82 %, patience  11 \n",
      "\n",
      "Epoch  39 , training err  37.472 %, val err  36.76 %, patience  10 \n",
      "\n",
      "Epoch  40 , training err  41.912 %, val err  40.99 %, patience  9 \n",
      "\n",
      "Epoch  41 , training err  35.878 %, val err  35.51 %, patience  20 \n",
      "\n",
      "Epoch  42 , training err  38.684 %, val err  38.33 %, patience  19 \n",
      "\n",
      "Epoch  43 , training err  39.976 %, val err  39.58 %, patience  18 \n",
      "\n",
      "Epoch  44 , training err  35.12 %, val err  35.25 %, patience  20 \n",
      "\n",
      "Epoch  45 , training err  38.466 %, val err  37.62 %, patience  19 \n",
      "\n",
      "Epoch  46 , training err  36.944 %, val err  36.7 %, patience  18 \n",
      "\n",
      "Epoch  47 , training err  34.506 %, val err  33.94 %, patience  20 \n",
      "\n",
      "Epoch  48 , training err  37.878 %, val err  37.12 %, patience  19 \n",
      "\n",
      "Epoch  49 , training err  36.902 %, val err  36.3 %, patience  18 \n",
      "\n",
      "Epoch  50 , training err  44.08 %, val err  42.96 %, patience  17 \n",
      "\n",
      "Epoch  51 , training err  37.15 %, val err  36.65 %, patience  16 \n",
      "\n",
      "Epoch  52 , training err  36.492 %, val err  35.75 %, patience  15 \n",
      "\n",
      "Epoch  53 , training err  39.302 %, val err  38.26 %, patience  14 \n",
      "\n",
      "Epoch  54 , training err  37.302 %, val err  36.69 %, patience  13 \n",
      "\n",
      "Epoch  55 , training err  35.688 %, val err  35.25 %, patience  12 \n",
      "\n",
      "Epoch  56 , training err  34.32 %, val err  34.29 %, patience  11 \n",
      "\n",
      "Epoch  57 , training err  36.66 %, val err  35.81 %, patience  10 \n",
      "\n",
      "Epoch  58 , training err  42.636 %, val err  42.17 %, patience  9 \n",
      "\n",
      "Epoch  59 , training err  39.044 %, val err  38.13 %, patience  8 \n",
      "\n",
      "Epoch  60 , training err  36.17 %, val err  35.94 %, patience  7 \n",
      "\n",
      "Epoch  61 , training err  36.338 %, val err  35.51 %, patience  6 \n",
      "\n",
      "Epoch  62 , training err  37.476 %, val err  37.06 %, patience  5 \n",
      "\n",
      "Epoch  63 , training err  37.034 %, val err  36.15 %, patience  4 \n",
      "\n",
      "Epoch  64 , training err  40.458 %, val err  39.8 %, patience  3 \n",
      "\n",
      "Epoch  65 , training err  35.912 %, val err  35.46 %, patience  2 \n",
      "\n",
      "Epoch  66 , training err  38.97 %, val err  38.29 %, patience  1 \n",
      "\n",
      "Epoch  67 , training err  39.628 %, val err  39.08 %, patience  0 \n",
      "\n",
      "Best val err  33.94 % at epoch  47  corresponding train err  34.506 %\n",
      "Epoch  0 , training err  14.546 %, val err  13.37 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  11.832 %, val err  11.05 %, patience  20 \n",
      "\n",
      "Epoch  2 , training err  11.814 %, val err  11.07 %, patience  19 \n",
      "\n",
      "Epoch  3 , training err  11.684 %, val err  11.18 %, patience  18 \n",
      "\n",
      "Epoch  4 , training err  11.246 %, val err  10.85 %, patience  20 \n",
      "\n",
      "Epoch  5 , training err  10.49 %, val err  10.36 %, patience  20 \n",
      "\n",
      "Epoch  6 , training err  10.718 %, val err  10.5 %, patience  19 \n",
      "\n",
      "Epoch  7 , training err  11.032 %, val err  10.97 %, patience  18 \n",
      "\n",
      "Epoch  8 , training err  10.188 %, val err  10.43 %, patience  17 \n",
      "\n",
      "Epoch  9 , training err  10.074 %, val err  10.01 %, patience  20 \n",
      "\n",
      "Epoch  10 , training err  10.216 %, val err  9.99 %, patience  20 \n",
      "\n",
      "Epoch  11 , training err  10.034 %, val err  9.69 %, patience  20 \n",
      "\n",
      "Epoch  12 , training err  10.296 %, val err  10.01 %, patience  19 \n",
      "\n",
      "Epoch  13 , training err  10.996 %, val err  10.82 %, patience  18 \n",
      "\n",
      "Epoch  14 , training err  10.368 %, val err  10.19 %, patience  17 \n",
      "\n",
      "Epoch  15 , training err  10.352 %, val err  10.24 %, patience  16 \n",
      "\n",
      "Epoch  16 , training err  10.878 %, val err  10.28 %, patience  15 \n",
      "\n",
      "Epoch  17 , training err  10.146 %, val err  9.96 %, patience  14 \n",
      "\n",
      "Epoch  18 , training err  10.47 %, val err  10.41 %, patience  13 \n",
      "\n",
      "Epoch  19 , training err  10.254 %, val err  10.13 %, patience  12 \n",
      "\n",
      "Epoch  20 , training err  11.086 %, val err  10.93 %, patience  11 \n",
      "\n",
      "Epoch  21 , training err  10.344 %, val err  10.23 %, patience  10 \n",
      "\n",
      "Epoch  22 , training err  10.648 %, val err  10.46 %, patience  9 \n",
      "\n",
      "Epoch  23 , training err  9.954 %, val err  9.86 %, patience  8 \n",
      "\n",
      "Epoch  24 , training err  10.102 %, val err  9.94 %, patience  7 \n",
      "\n",
      "Epoch  25 , training err  10.678 %, val err  10.43 %, patience  6 \n",
      "\n",
      "Epoch  26 , training err  11.004 %, val err  10.7 %, patience  5 \n",
      "\n",
      "Epoch  27 , training err  10.266 %, val err  10.23 %, patience  4 \n",
      "\n",
      "Epoch  28 , training err  10.832 %, val err  10.81 %, patience  3 \n",
      "\n",
      "Epoch  29 , training err  10.242 %, val err  10.02 %, patience  2 \n",
      "\n",
      "Epoch  30 , training err  9.842 %, val err  9.72 %, patience  1 \n",
      "\n",
      "Epoch  31 , training err  10.254 %, val err  10.27 %, patience  0 \n",
      "\n",
      "Best val err  9.69 % at epoch  11  corresponding train err  10.034 %\n",
      "Epoch  0 , training err  8.964 %, val err  8.64 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  7.452 %, val err  7.61 %, patience  20 \n",
      "\n",
      "Epoch  2 , training err  6.96 %, val err  7.13 %, patience  20 \n",
      "\n",
      "Epoch  3 , training err  6.118 %, val err  6.35 %, patience  20 \n",
      "\n",
      "Epoch  4 , training err  5.92 %, val err  5.95 %, patience  20 \n",
      "\n",
      "Epoch  5 , training err  5.786 %, val err  6.21 %, patience  19 \n",
      "\n",
      "Epoch  6 , training err  5.832 %, val err  6.18 %, patience  18 \n",
      "\n",
      "Epoch  7 , training err  5.388 %, val err  5.79 %, patience  20 \n",
      "\n",
      "Epoch  8 , training err  5.45 %, val err  5.79 %, patience  19 \n",
      "\n",
      "Epoch  9 , training err  5.142 %, val err  5.56 %, patience  20 \n",
      "\n",
      "Epoch  10 , training err  5.144 %, val err  5.48 %, patience  20 \n",
      "\n",
      "Epoch  11 , training err  4.93 %, val err  5.3 %, patience  20 \n",
      "\n",
      "Epoch  12 , training err  5.23 %, val err  5.74 %, patience  19 \n",
      "\n",
      "Epoch  13 , training err  4.926 %, val err  5.44 %, patience  18 \n",
      "\n",
      "Epoch  14 , training err  5.006 %, val err  5.52 %, patience  17 \n",
      "\n",
      "Epoch  15 , training err  4.712 %, val err  5.28 %, patience  20 \n",
      "\n",
      "Epoch  16 , training err  4.658 %, val err  5.14 %, patience  20 \n",
      "\n",
      "Epoch  17 , training err  4.64 %, val err  5.13 %, patience  20 \n",
      "\n",
      "Epoch  18 , training err  4.984 %, val err  5.61 %, patience  19 \n",
      "\n",
      "Epoch  19 , training err  4.926 %, val err  5.32 %, patience  18 \n",
      "\n",
      "Epoch  20 , training err  4.79 %, val err  5.47 %, patience  17 \n",
      "\n",
      "Epoch  21 , training err  4.694 %, val err  5.11 %, patience  20 \n",
      "\n",
      "Epoch  22 , training err  4.75 %, val err  5.32 %, patience  19 \n",
      "\n",
      "Epoch  23 , training err  4.514 %, val err  4.9 %, patience  20 \n",
      "\n",
      "Epoch  24 , training err  4.438 %, val err  5.07 %, patience  19 \n",
      "\n",
      "Epoch  25 , training err  4.558 %, val err  5.01 %, patience  18 \n",
      "\n",
      "Epoch  26 , training err  4.328 %, val err  4.99 %, patience  17 \n",
      "\n",
      "Epoch  27 , training err  4.522 %, val err  4.97 %, patience  16 \n",
      "\n",
      "Epoch  28 , training err  4.408 %, val err  4.93 %, patience  15 \n",
      "\n",
      "Epoch  29 , training err  4.322 %, val err  4.97 %, patience  14 \n",
      "\n",
      "Epoch  30 , training err  4.682 %, val err  5.13 %, patience  13 \n",
      "\n",
      "Epoch  31 , training err  4.6 %, val err  5.25 %, patience  12 \n",
      "\n",
      "Epoch  32 , training err  4.318 %, val err  4.8 %, patience  20 \n",
      "\n",
      "Epoch  33 , training err  4.482 %, val err  5.04 %, patience  19 \n",
      "\n",
      "Epoch  34 , training err  4.202 %, val err  4.96 %, patience  18 \n",
      "\n",
      "Epoch  35 , training err  4.642 %, val err  5.14 %, patience  17 \n",
      "\n",
      "Epoch  36 , training err  4.478 %, val err  5.31 %, patience  16 \n",
      "\n",
      "Epoch  37 , training err  4.368 %, val err  4.93 %, patience  15 \n",
      "\n",
      "Epoch  38 , training err  4.704 %, val err  5.26 %, patience  14 \n",
      "\n",
      "Epoch  39 , training err  4.13 %, val err  4.75 %, patience  20 \n",
      "\n",
      "Epoch  40 , training err  4.288 %, val err  4.9 %, patience  19 \n",
      "\n",
      "Epoch  41 , training err  4.528 %, val err  4.93 %, patience  18 \n",
      "\n",
      "Epoch  42 , training err  4.176 %, val err  4.82 %, patience  17 \n",
      "\n",
      "Epoch  43 , training err  4.448 %, val err  4.95 %, patience  16 \n",
      "\n",
      "Epoch  44 , training err  4.326 %, val err  5.0 %, patience  15 \n",
      "\n",
      "Epoch  45 , training err  4.222 %, val err  4.71 %, patience  20 \n",
      "\n",
      "Epoch  46 , training err  4.09 %, val err  4.78 %, patience  19 \n",
      "\n",
      "Epoch  47 , training err  4.256 %, val err  4.97 %, patience  18 \n",
      "\n",
      "Epoch  48 , training err  4.302 %, val err  4.88 %, patience  17 \n",
      "\n",
      "Epoch  49 , training err  4.168 %, val err  4.76 %, patience  16 \n",
      "\n",
      "Epoch  50 , training err  4.144 %, val err  4.79 %, patience  15 \n",
      "\n",
      "Epoch  51 , training err  4.054 %, val err  4.74 %, patience  14 \n",
      "\n",
      "Epoch  52 , training err  4.17 %, val err  4.93 %, patience  13 \n",
      "\n",
      "Epoch  53 , training err  4.07 %, val err  4.79 %, patience  12 \n",
      "\n",
      "Epoch  54 , training err  4.236 %, val err  4.75 %, patience  11 \n",
      "\n",
      "Epoch  55 , training err  4.258 %, val err  5.09 %, patience  10 \n",
      "\n",
      "Epoch  56 , training err  4.108 %, val err  4.88 %, patience  9 \n",
      "\n",
      "Epoch  57 , training err  4.212 %, val err  4.75 %, patience  8 \n",
      "\n",
      "Epoch  58 , training err  4.18 %, val err  4.93 %, patience  7 \n",
      "\n",
      "Epoch  59 , training err  4.028 %, val err  4.75 %, patience  6 \n",
      "\n",
      "Epoch  60 , training err  4.128 %, val err  4.8 %, patience  5 \n",
      "\n",
      "Epoch  61 , training err  4.158 %, val err  4.68 %, patience  20 \n",
      "\n",
      "Epoch  62 , training err  4.336 %, val err  4.89 %, patience  19 \n",
      "\n",
      "Epoch  63 , training err  4.018 %, val err  4.72 %, patience  18 \n",
      "\n",
      "Epoch  64 , training err  4.014 %, val err  4.69 %, patience  17 \n",
      "\n",
      "Epoch  65 , training err  4.002 %, val err  4.84 %, patience  16 \n",
      "\n",
      "Epoch  66 , training err  4.05 %, val err  4.77 %, patience  15 \n",
      "\n",
      "Epoch  67 , training err  4.026 %, val err  4.67 %, patience  20 \n",
      "\n",
      "Epoch  68 , training err  4.088 %, val err  4.88 %, patience  19 \n",
      "\n",
      "Epoch  69 , training err  4.234 %, val err  4.82 %, patience  18 \n",
      "\n",
      "Epoch  70 , training err  3.898 %, val err  4.67 %, patience  17 \n",
      "\n",
      "Epoch  71 , training err  4.082 %, val err  4.95 %, patience  16 \n",
      "\n",
      "Epoch  72 , training err  4.04 %, val err  4.67 %, patience  15 \n",
      "\n",
      "Epoch  73 , training err  4.166 %, val err  4.73 %, patience  14 \n",
      "\n",
      "Epoch  74 , training err  4.202 %, val err  4.79 %, patience  13 \n",
      "\n",
      "Epoch  75 , training err  4.242 %, val err  4.99 %, patience  12 \n",
      "\n",
      "Epoch  76 , training err  3.882 %, val err  4.54 %, patience  20 \n",
      "\n",
      "Epoch  77 , training err  4.072 %, val err  4.65 %, patience  19 \n",
      "\n",
      "Epoch  78 , training err  3.99 %, val err  4.78 %, patience  18 \n",
      "\n",
      "Epoch  79 , training err  3.86 %, val err  4.54 %, patience  17 \n",
      "\n",
      "Epoch  80 , training err  4.028 %, val err  4.63 %, patience  16 \n",
      "\n",
      "Epoch  81 , training err  4.042 %, val err  4.76 %, patience  15 \n",
      "\n",
      "Epoch  82 , training err  3.814 %, val err  4.66 %, patience  14 \n",
      "\n",
      "Epoch  83 , training err  4.288 %, val err  4.91 %, patience  13 \n",
      "\n",
      "Epoch  84 , training err  4.06 %, val err  4.83 %, patience  12 \n",
      "\n",
      "Epoch  85 , training err  4.066 %, val err  4.77 %, patience  11 \n",
      "\n",
      "Epoch  86 , training err  3.842 %, val err  4.63 %, patience  10 \n",
      "\n",
      "Epoch  87 , training err  4.144 %, val err  4.84 %, patience  9 \n",
      "\n",
      "Epoch  88 , training err  3.894 %, val err  4.54 %, patience  8 \n",
      "\n",
      "Epoch  89 , training err  3.866 %, val err  4.48 %, patience  20 \n",
      "\n",
      "Epoch  90 , training err  3.974 %, val err  4.66 %, patience  19 \n",
      "\n",
      "Epoch  91 , training err  4.01 %, val err  4.51 %, patience  18 \n",
      "\n",
      "Epoch  92 , training err  3.992 %, val err  4.47 %, patience  20 \n",
      "\n",
      "Epoch  93 , training err  4.148 %, val err  4.6 %, patience  19 \n",
      "\n",
      "Epoch  94 , training err  3.876 %, val err  4.49 %, patience  18 \n",
      "\n",
      "Epoch  95 , training err  3.814 %, val err  4.52 %, patience  17 \n",
      "\n",
      "Epoch  96 , training err  4.016 %, val err  4.6 %, patience  16 \n",
      "\n",
      "Epoch  97 , training err  3.864 %, val err  4.6 %, patience  15 \n",
      "\n",
      "Epoch  98 , training err  4.22 %, val err  4.9 %, patience  14 \n",
      "\n",
      "Epoch  99 , training err  3.868 %, val err  4.57 %, patience  13 \n",
      "\n",
      "Epoch  100 , training err  3.808 %, val err  4.45 %, patience  20 \n",
      "\n",
      "Epoch  101 , training err  4.066 %, val err  4.67 %, patience  19 \n",
      "\n",
      "Epoch  102 , training err  3.82 %, val err  4.52 %, patience  18 \n",
      "\n",
      "Epoch  103 , training err  3.984 %, val err  4.56 %, patience  17 \n",
      "\n",
      "Epoch  104 , training err  3.984 %, val err  4.6 %, patience  16 \n",
      "\n",
      "Epoch  105 , training err  3.868 %, val err  4.63 %, patience  15 \n",
      "\n",
      "Epoch  106 , training err  3.772 %, val err  4.52 %, patience  14 \n",
      "\n",
      "Epoch  107 , training err  3.896 %, val err  4.71 %, patience  13 \n",
      "\n",
      "Epoch  108 , training err  3.914 %, val err  4.71 %, patience  12 \n",
      "\n",
      "Epoch  109 , training err  4.106 %, val err  4.72 %, patience  11 \n",
      "\n",
      "Epoch  110 , training err  4.054 %, val err  4.68 %, patience  10 \n",
      "\n",
      "Epoch  111 , training err  3.848 %, val err  4.59 %, patience  9 \n",
      "\n",
      "Epoch  112 , training err  3.82 %, val err  4.38 %, patience  20 \n",
      "\n",
      "Epoch  113 , training err  3.9 %, val err  4.67 %, patience  19 \n",
      "\n",
      "Epoch  114 , training err  3.93 %, val err  4.53 %, patience  18 \n",
      "\n",
      "Epoch  115 , training err  3.916 %, val err  4.61 %, patience  17 \n",
      "\n",
      "Epoch  116 , training err  4.014 %, val err  4.61 %, patience  16 \n",
      "\n",
      "Epoch  117 , training err  3.996 %, val err  4.56 %, patience  15 \n",
      "\n",
      "Epoch  118 , training err  3.832 %, val err  4.55 %, patience  14 \n",
      "\n",
      "Epoch  119 , training err  3.822 %, val err  4.44 %, patience  13 \n",
      "\n",
      "Epoch  120 , training err  3.902 %, val err  4.67 %, patience  12 \n",
      "\n",
      "Epoch  121 , training err  3.754 %, val err  4.46 %, patience  11 \n",
      "\n",
      "Epoch  122 , training err  3.732 %, val err  4.39 %, patience  10 \n",
      "\n",
      "Epoch  123 , training err  3.894 %, val err  4.53 %, patience  9 \n",
      "\n",
      "Epoch  124 , training err  3.88 %, val err  4.68 %, patience  8 \n",
      "\n",
      "Epoch  125 , training err  3.812 %, val err  4.47 %, patience  7 \n",
      "\n",
      "Epoch  126 , training err  3.724 %, val err  4.38 %, patience  6 \n",
      "\n",
      "Epoch  127 , training err  4.014 %, val err  4.59 %, patience  5 \n",
      "\n",
      "Epoch  128 , training err  3.944 %, val err  4.54 %, patience  4 \n",
      "\n",
      "Epoch  129 , training err  3.816 %, val err  4.41 %, patience  3 \n",
      "\n",
      "Epoch  130 , training err  3.776 %, val err  4.52 %, patience  2 \n",
      "\n",
      "Epoch  131 , training err  4.112 %, val err  4.89 %, patience  1 \n",
      "\n",
      "Epoch  132 , training err  3.81 %, val err  4.58 %, patience  0 \n",
      "\n",
      "Best val err  4.38 % at epoch  112  corresponding train err  3.82 %\n",
      "Epoch  0 , training err  7.868 %, val err  7.14 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  6.41 %, val err  5.9 %, patience  20 \n",
      "\n",
      "Epoch  2 , training err  5.35 %, val err  5.27 %, patience  20 \n",
      "\n",
      "Epoch  3 , training err  5.154 %, val err  5.14 %, patience  20 \n",
      "\n",
      "Epoch  4 , training err  4.652 %, val err  4.74 %, patience  20 \n",
      "\n",
      "Epoch  5 , training err  4.574 %, val err  4.7 %, patience  20 \n",
      "\n",
      "Epoch  6 , training err  4.476 %, val err  4.69 %, patience  20 \n",
      "\n",
      "Epoch  7 , training err  4.228 %, val err  4.35 %, patience  20 \n",
      "\n",
      "Epoch  8 , training err  4.244 %, val err  4.44 %, patience  19 \n",
      "\n",
      "Epoch  9 , training err  4.01 %, val err  4.45 %, patience  18 \n",
      "\n",
      "Epoch  10 , training err  4.28 %, val err  4.72 %, patience  17 \n",
      "\n",
      "Epoch  11 , training err  3.918 %, val err  4.2 %, patience  20 \n",
      "\n",
      "Epoch  12 , training err  3.736 %, val err  4.35 %, patience  19 \n",
      "\n",
      "Epoch  13 , training err  3.814 %, val err  4.44 %, patience  18 \n",
      "\n",
      "Epoch  14 , training err  3.884 %, val err  4.51 %, patience  17 \n",
      "\n",
      "Epoch  15 , training err  3.878 %, val err  4.47 %, patience  16 \n",
      "\n",
      "Epoch  16 , training err  3.708 %, val err  4.49 %, patience  15 \n",
      "\n",
      "Epoch  17 , training err  3.692 %, val err  4.38 %, patience  14 \n",
      "\n",
      "Epoch  18 , training err  3.616 %, val err  4.12 %, patience  20 \n",
      "\n",
      "Epoch  19 , training err  3.672 %, val err  4.46 %, patience  19 \n",
      "\n",
      "Epoch  20 , training err  3.404 %, val err  4.3 %, patience  18 \n",
      "\n",
      "Epoch  21 , training err  3.56 %, val err  4.07 %, patience  20 \n",
      "\n",
      "Epoch  22 , training err  3.444 %, val err  3.91 %, patience  20 \n",
      "\n",
      "Epoch  23 , training err  3.542 %, val err  4.27 %, patience  19 \n",
      "\n",
      "Epoch  24 , training err  3.396 %, val err  4.2 %, patience  18 \n",
      "\n",
      "Epoch  25 , training err  3.582 %, val err  4.25 %, patience  17 \n",
      "\n",
      "Epoch  26 , training err  3.428 %, val err  4.09 %, patience  16 \n",
      "\n",
      "Epoch  27 , training err  3.43 %, val err  4.12 %, patience  15 \n",
      "\n",
      "Epoch  28 , training err  3.574 %, val err  4.21 %, patience  14 \n",
      "\n",
      "Epoch  29 , training err  3.76 %, val err  4.67 %, patience  13 \n",
      "\n",
      "Epoch  30 , training err  3.398 %, val err  4.08 %, patience  12 \n",
      "\n",
      "Epoch  31 , training err  3.332 %, val err  4.0 %, patience  11 \n",
      "\n",
      "Epoch  32 , training err  3.542 %, val err  4.23 %, patience  10 \n",
      "\n",
      "Epoch  33 , training err  3.382 %, val err  4.03 %, patience  9 \n",
      "\n",
      "Epoch  34 , training err  3.53 %, val err  4.33 %, patience  8 \n",
      "\n",
      "Epoch  35 , training err  3.406 %, val err  4.15 %, patience  7 \n",
      "\n",
      "Epoch  36 , training err  3.378 %, val err  4.07 %, patience  6 \n",
      "\n",
      "Epoch  37 , training err  3.446 %, val err  4.17 %, patience  5 \n",
      "\n",
      "Epoch  38 , training err  3.414 %, val err  4.09 %, patience  4 \n",
      "\n",
      "Epoch  39 , training err  3.382 %, val err  4.16 %, patience  3 \n",
      "\n",
      "Epoch  40 , training err  3.34 %, val err  4.19 %, patience  2 \n",
      "\n",
      "Epoch  41 , training err  3.412 %, val err  4.07 %, patience  1 \n",
      "\n",
      "Epoch  42 , training err  3.314 %, val err  4.13 %, patience  0 \n",
      "\n",
      "Best val err  3.91 % at epoch  22  corresponding train err  3.444 %\n",
      "Epoch  0 , training err  7.48 %, val err  7.03 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  5.968 %, val err  5.82 %, patience  20 \n",
      "\n",
      "Epoch  2 , training err  5.244 %, val err  5.27 %, patience  20 \n",
      "\n",
      "Epoch  3 , training err  4.756 %, val err  4.88 %, patience  20 \n",
      "\n",
      "Epoch  4 , training err  4.424 %, val err  4.85 %, patience  20 \n",
      "\n",
      "Epoch  5 , training err  3.936 %, val err  4.37 %, patience  20 \n",
      "\n",
      "Epoch  6 , training err  3.782 %, val err  4.27 %, patience  20 \n",
      "\n",
      "Epoch  7 , training err  3.596 %, val err  3.99 %, patience  20 \n",
      "\n",
      "Epoch  8 , training err  3.58 %, val err  4.07 %, patience  19 \n",
      "\n",
      "Epoch  9 , training err  3.428 %, val err  3.76 %, patience  20 \n",
      "\n",
      "Epoch  10 , training err  3.258 %, val err  3.95 %, patience  19 \n",
      "\n",
      "Epoch  11 , training err  3.112 %, val err  3.71 %, patience  20 \n",
      "\n",
      "Epoch  12 , training err  3.044 %, val err  3.87 %, patience  19 \n",
      "\n",
      "Epoch  13 , training err  2.86 %, val err  3.56 %, patience  20 \n",
      "\n",
      "Epoch  14 , training err  2.978 %, val err  3.82 %, patience  19 \n",
      "\n",
      "Epoch  15 , training err  2.824 %, val err  3.64 %, patience  18 \n",
      "\n",
      "Epoch  16 , training err  2.848 %, val err  3.73 %, patience  17 \n",
      "\n",
      "Epoch  17 , training err  2.8 %, val err  3.64 %, patience  16 \n",
      "\n",
      "Epoch  18 , training err  2.8 %, val err  3.84 %, patience  15 \n",
      "\n",
      "Epoch  19 , training err  2.728 %, val err  3.63 %, patience  14 \n",
      "\n",
      "Epoch  20 , training err  2.724 %, val err  3.71 %, patience  13 \n",
      "\n",
      "Epoch  21 , training err  2.63 %, val err  3.65 %, patience  12 \n",
      "\n",
      "Epoch  22 , training err  2.78 %, val err  3.67 %, patience  11 \n",
      "\n",
      "Epoch  23 , training err  2.606 %, val err  3.45 %, patience  20 \n",
      "\n",
      "Epoch  24 , training err  2.54 %, val err  3.4 %, patience  20 \n",
      "\n",
      "Epoch  25 , training err  2.558 %, val err  3.49 %, patience  19 \n",
      "\n",
      "Epoch  26 , training err  2.526 %, val err  3.34 %, patience  20 \n",
      "\n",
      "Epoch  27 , training err  2.586 %, val err  3.6 %, patience  19 \n",
      "\n",
      "Epoch  28 , training err  2.546 %, val err  3.55 %, patience  18 \n",
      "\n",
      "Epoch  29 , training err  2.564 %, val err  3.43 %, patience  17 \n",
      "\n",
      "Epoch  30 , training err  2.576 %, val err  3.45 %, patience  16 \n",
      "\n",
      "Epoch  31 , training err  2.646 %, val err  3.44 %, patience  15 \n",
      "\n",
      "Epoch  32 , training err  2.442 %, val err  3.48 %, patience  14 \n",
      "\n",
      "Epoch  33 , training err  2.682 %, val err  3.55 %, patience  13 \n",
      "\n",
      "Epoch  34 , training err  2.584 %, val err  3.46 %, patience  12 \n",
      "\n",
      "Epoch  35 , training err  2.43 %, val err  3.39 %, patience  11 \n",
      "\n",
      "Epoch  36 , training err  2.394 %, val err  3.31 %, patience  20 \n",
      "\n",
      "Epoch  37 , training err  2.422 %, val err  3.44 %, patience  19 \n",
      "\n",
      "Epoch  38 , training err  2.372 %, val err  3.26 %, patience  20 \n",
      "\n",
      "Epoch  39 , training err  2.57 %, val err  3.34 %, patience  19 \n",
      "\n",
      "Epoch  40 , training err  2.47 %, val err  3.4 %, patience  18 \n",
      "\n",
      "Epoch  41 , training err  2.5 %, val err  3.42 %, patience  17 \n",
      "\n",
      "Epoch  42 , training err  2.438 %, val err  3.4 %, patience  16 \n",
      "\n",
      "Epoch  43 , training err  2.454 %, val err  3.26 %, patience  15 \n",
      "\n",
      "Epoch  44 , training err  2.58 %, val err  3.46 %, patience  14 \n",
      "\n",
      "Epoch  45 , training err  2.63 %, val err  3.53 %, patience  13 \n",
      "\n",
      "Epoch  46 , training err  2.5 %, val err  3.5 %, patience  12 \n",
      "\n",
      "Epoch  47 , training err  2.332 %, val err  3.4 %, patience  11 \n",
      "\n",
      "Epoch  48 , training err  2.408 %, val err  3.34 %, patience  10 \n",
      "\n",
      "Epoch  49 , training err  2.496 %, val err  3.38 %, patience  9 \n",
      "\n",
      "Epoch  50 , training err  2.666 %, val err  3.58 %, patience  8 \n",
      "\n",
      "Epoch  51 , training err  2.418 %, val err  3.36 %, patience  7 \n",
      "\n",
      "Epoch  52 , training err  2.584 %, val err  3.52 %, patience  6 \n",
      "\n",
      "Epoch  53 , training err  2.404 %, val err  3.48 %, patience  5 \n",
      "\n",
      "Epoch  54 , training err  2.406 %, val err  3.36 %, patience  4 \n",
      "\n",
      "Epoch  55 , training err  2.296 %, val err  3.12 %, patience  20 \n",
      "\n",
      "Epoch  56 , training err  2.344 %, val err  3.26 %, patience  19 \n",
      "\n",
      "Epoch  57 , training err  2.28 %, val err  3.23 %, patience  18 \n",
      "\n",
      "Epoch  58 , training err  2.278 %, val err  3.36 %, patience  17 \n",
      "\n",
      "Epoch  59 , training err  2.522 %, val err  3.49 %, patience  16 \n",
      "\n",
      "Epoch  60 , training err  2.358 %, val err  3.44 %, patience  15 \n",
      "\n",
      "Epoch  61 , training err  2.39 %, val err  3.46 %, patience  14 \n",
      "\n",
      "Epoch  62 , training err  2.306 %, val err  3.27 %, patience  13 \n",
      "\n",
      "Epoch  63 , training err  2.332 %, val err  3.52 %, patience  12 \n",
      "\n",
      "Epoch  64 , training err  2.356 %, val err  3.2 %, patience  11 \n",
      "\n",
      "Epoch  65 , training err  2.496 %, val err  3.49 %, patience  10 \n",
      "\n",
      "Epoch  66 , training err  2.196 %, val err  3.32 %, patience  9 \n",
      "\n",
      "Epoch  67 , training err  2.382 %, val err  3.26 %, patience  8 \n",
      "\n",
      "Epoch  68 , training err  2.506 %, val err  3.32 %, patience  7 \n",
      "\n",
      "Epoch  69 , training err  2.098 %, val err  3.06 %, patience  20 \n",
      "\n",
      "Epoch  70 , training err  2.23 %, val err  3.25 %, patience  19 \n",
      "\n",
      "Epoch  71 , training err  2.378 %, val err  3.43 %, patience  18 \n",
      "\n",
      "Epoch  72 , training err  2.288 %, val err  3.14 %, patience  17 \n",
      "\n",
      "Epoch  73 , training err  2.434 %, val err  3.42 %, patience  16 \n",
      "\n",
      "Epoch  74 , training err  2.384 %, val err  3.31 %, patience  15 \n",
      "\n",
      "Epoch  75 , training err  2.16 %, val err  3.08 %, patience  14 \n",
      "\n",
      "Epoch  76 , training err  2.298 %, val err  3.33 %, patience  13 \n",
      "\n",
      "Epoch  77 , training err  2.324 %, val err  3.19 %, patience  12 \n",
      "\n",
      "Epoch  78 , training err  2.072 %, val err  3.04 %, patience  20 \n",
      "\n",
      "Epoch  79 , training err  2.306 %, val err  3.14 %, patience  19 \n",
      "\n",
      "Epoch  80 , training err  2.204 %, val err  3.24 %, patience  18 \n",
      "\n",
      "Epoch  81 , training err  2.25 %, val err  3.19 %, patience  17 \n",
      "\n",
      "Epoch  82 , training err  2.12 %, val err  3.05 %, patience  16 \n",
      "\n",
      "Epoch  83 , training err  2.23 %, val err  3.06 %, patience  15 \n",
      "\n",
      "Epoch  84 , training err  2.236 %, val err  3.2 %, patience  14 \n",
      "\n",
      "Epoch  85 , training err  2.072 %, val err  3.03 %, patience  20 \n",
      "\n",
      "Epoch  86 , training err  2.28 %, val err  3.29 %, patience  19 \n",
      "\n",
      "Epoch  87 , training err  2.196 %, val err  3.21 %, patience  18 \n",
      "\n",
      "Epoch  88 , training err  2.12 %, val err  3.16 %, patience  17 \n",
      "\n",
      "Epoch  89 , training err  2.172 %, val err  3.21 %, patience  16 \n",
      "\n",
      "Epoch  90 , training err  2.426 %, val err  3.45 %, patience  15 \n",
      "\n",
      "Epoch  91 , training err  2.168 %, val err  3.23 %, patience  14 \n",
      "\n",
      "Epoch  92 , training err  2.142 %, val err  3.22 %, patience  13 \n",
      "\n",
      "Epoch  93 , training err  2.074 %, val err  3.11 %, patience  12 \n",
      "\n",
      "Epoch  94 , training err  2.208 %, val err  3.13 %, patience  11 \n",
      "\n",
      "Epoch  95 , training err  2.248 %, val err  3.18 %, patience  10 \n",
      "\n",
      "Epoch  96 , training err  2.218 %, val err  3.21 %, patience  9 \n",
      "\n",
      "Epoch  97 , training err  2.184 %, val err  3.07 %, patience  8 \n",
      "\n",
      "Epoch  98 , training err  2.166 %, val err  3.11 %, patience  7 \n",
      "\n",
      "Epoch  99 , training err  2.116 %, val err  3.16 %, patience  6 \n",
      "\n",
      "Epoch  100 , training err  2.186 %, val err  3.06 %, patience  5 \n",
      "\n",
      "Epoch  101 , training err  2.324 %, val err  2.98 %, patience  20 \n",
      "\n",
      "Epoch  102 , training err  2.218 %, val err  3.08 %, patience  19 \n",
      "\n",
      "Epoch  103 , training err  2.246 %, val err  3.26 %, patience  18 \n",
      "\n",
      "Epoch  104 , training err  2.212 %, val err  3.12 %, patience  17 \n",
      "\n",
      "Epoch  105 , training err  2.16 %, val err  2.96 %, patience  20 \n",
      "\n",
      "Epoch  106 , training err  2.302 %, val err  3.18 %, patience  19 \n",
      "\n",
      "Epoch  107 , training err  2.252 %, val err  3.27 %, patience  18 \n",
      "\n",
      "Epoch  108 , training err  2.22 %, val err  3.26 %, patience  17 \n",
      "\n",
      "Epoch  109 , training err  2.044 %, val err  3.0 %, patience  16 \n",
      "\n",
      "Epoch  110 , training err  2.148 %, val err  3.2 %, patience  15 \n",
      "\n",
      "Epoch  111 , training err  2.136 %, val err  2.98 %, patience  14 \n",
      "\n",
      "Epoch  112 , training err  2.114 %, val err  2.91 %, patience  20 \n",
      "\n",
      "Epoch  113 , training err  2.152 %, val err  3.09 %, patience  19 \n",
      "\n",
      "Epoch  114 , training err  2.144 %, val err  3.13 %, patience  18 \n",
      "\n",
      "Epoch  115 , training err  2.2 %, val err  3.23 %, patience  17 \n",
      "\n",
      "Epoch  116 , training err  2.164 %, val err  3.02 %, patience  16 \n",
      "\n",
      "Epoch  117 , training err  2.266 %, val err  3.08 %, patience  15 \n",
      "\n",
      "Epoch  118 , training err  2.112 %, val err  3.05 %, patience  14 \n",
      "\n",
      "Epoch  119 , training err  2.234 %, val err  3.16 %, patience  13 \n",
      "\n",
      "Epoch  120 , training err  2.444 %, val err  3.27 %, patience  12 \n",
      "\n",
      "Epoch  121 , training err  2.076 %, val err  3.08 %, patience  11 \n",
      "\n",
      "Epoch  122 , training err  2.146 %, val err  3.13 %, patience  10 \n",
      "\n",
      "Epoch  123 , training err  2.208 %, val err  3.13 %, patience  9 \n",
      "\n",
      "Epoch  124 , training err  2.234 %, val err  3.05 %, patience  8 \n",
      "\n",
      "Epoch  125 , training err  2.196 %, val err  3.1 %, patience  7 \n",
      "\n",
      "Epoch  126 , training err  2.096 %, val err  3.06 %, patience  6 \n",
      "\n",
      "Epoch  127 , training err  2.092 %, val err  3.1 %, patience  5 \n",
      "\n",
      "Epoch  128 , training err  2.07 %, val err  2.97 %, patience  4 \n",
      "\n",
      "Epoch  129 , training err  2.23 %, val err  3.12 %, patience  3 \n",
      "\n",
      "Epoch  130 , training err  2.134 %, val err  3.05 %, patience  2 \n",
      "\n",
      "Epoch  131 , training err  2.044 %, val err  3.1 %, patience  1 \n",
      "\n",
      "Epoch  132 , training err  2.138 %, val err  3.03 %, patience  0 \n",
      "\n",
      "Best val err  2.91 % at epoch  112  corresponding train err  2.114 %\n",
      "Epoch  0 , training err  7.384 %, val err  7.0 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  5.556 %, val err  5.31 %, patience  20 \n",
      "\n",
      "Epoch  2 , training err  4.988 %, val err  5.02 %, patience  20 \n",
      "\n",
      "Epoch  3 , training err  4.12 %, val err  4.2 %, patience  20 \n",
      "\n",
      "Epoch  4 , training err  3.842 %, val err  3.86 %, patience  20 \n",
      "\n",
      "Epoch  5 , training err  3.47 %, val err  3.68 %, patience  20 \n",
      "\n",
      "Epoch  6 , training err  3.308 %, val err  3.66 %, patience  20 \n",
      "\n",
      "Epoch  7 , training err  3.01 %, val err  3.46 %, patience  20 \n",
      "\n",
      "Epoch  8 , training err  2.988 %, val err  3.46 %, patience  19 \n",
      "\n",
      "Epoch  9 , training err  2.676 %, val err  3.25 %, patience  20 \n",
      "\n",
      "Epoch  10 , training err  2.658 %, val err  3.28 %, patience  19 \n",
      "\n",
      "Epoch  11 , training err  2.654 %, val err  3.29 %, patience  18 \n",
      "\n",
      "Epoch  12 , training err  2.484 %, val err  3.15 %, patience  20 \n",
      "\n",
      "Epoch  13 , training err  2.436 %, val err  3.19 %, patience  19 \n",
      "\n",
      "Epoch  14 , training err  2.526 %, val err  3.4 %, patience  18 \n",
      "\n",
      "Epoch  15 , training err  2.406 %, val err  3.16 %, patience  17 \n",
      "\n",
      "Epoch  16 , training err  2.328 %, val err  3.24 %, patience  16 \n",
      "\n",
      "Epoch  17 , training err  2.35 %, val err  3.3 %, patience  15 \n",
      "\n",
      "Epoch  18 , training err  2.234 %, val err  3.12 %, patience  20 \n",
      "\n",
      "Epoch  19 , training err  2.202 %, val err  3.14 %, patience  19 \n",
      "\n",
      "Epoch  20 , training err  2.166 %, val err  3.1 %, patience  20 \n",
      "\n",
      "Epoch  21 , training err  2.36 %, val err  3.21 %, patience  19 \n",
      "\n",
      "Epoch  22 , training err  2.144 %, val err  2.95 %, patience  20 \n",
      "\n",
      "Epoch  23 , training err  2.114 %, val err  3.02 %, patience  19 \n",
      "\n",
      "Epoch  24 , training err  2.078 %, val err  3.04 %, patience  18 \n",
      "\n",
      "Epoch  25 , training err  2.238 %, val err  3.19 %, patience  17 \n",
      "\n",
      "Epoch  26 , training err  1.974 %, val err  2.9 %, patience  20 \n",
      "\n",
      "Epoch  27 , training err  2.362 %, val err  3.34 %, patience  19 \n",
      "\n",
      "Epoch  28 , training err  2.154 %, val err  3.09 %, patience  18 \n",
      "\n",
      "Epoch  29 , training err  2.092 %, val err  3.03 %, patience  17 \n",
      "\n",
      "Epoch  30 , training err  2.316 %, val err  3.23 %, patience  16 \n",
      "\n",
      "Epoch  31 , training err  2.082 %, val err  3.13 %, patience  15 \n",
      "\n",
      "Epoch  32 , training err  1.964 %, val err  2.98 %, patience  14 \n",
      "\n",
      "Epoch  33 , training err  2.012 %, val err  3.08 %, patience  13 \n",
      "\n",
      "Epoch  34 , training err  2.25 %, val err  3.1 %, patience  12 \n",
      "\n",
      "Epoch  35 , training err  1.932 %, val err  2.98 %, patience  11 \n",
      "\n",
      "Epoch  36 , training err  1.97 %, val err  2.89 %, patience  20 \n",
      "\n",
      "Epoch  37 , training err  1.9 %, val err  2.79 %, patience  20 \n",
      "\n",
      "Epoch  38 , training err  2.07 %, val err  2.94 %, patience  19 \n",
      "\n",
      "Epoch  39 , training err  1.906 %, val err  2.89 %, patience  18 \n",
      "\n",
      "Epoch  40 , training err  1.982 %, val err  2.89 %, patience  17 \n",
      "\n",
      "Epoch  41 , training err  2.02 %, val err  2.88 %, patience  16 \n",
      "\n",
      "Epoch  42 , training err  1.972 %, val err  3.17 %, patience  15 \n",
      "\n",
      "Epoch  43 , training err  1.892 %, val err  2.86 %, patience  14 \n",
      "\n",
      "Epoch  44 , training err  1.86 %, val err  2.79 %, patience  13 \n",
      "\n",
      "Epoch  45 , training err  2.192 %, val err  2.94 %, patience  12 \n",
      "\n",
      "Epoch  46 , training err  1.938 %, val err  2.94 %, patience  11 \n",
      "\n",
      "Epoch  47 , training err  1.916 %, val err  2.88 %, patience  10 \n",
      "\n",
      "Epoch  48 , training err  1.818 %, val err  2.78 %, patience  20 \n",
      "\n",
      "Epoch  49 , training err  2.008 %, val err  2.9 %, patience  19 \n",
      "\n",
      "Epoch  50 , training err  2.018 %, val err  2.98 %, patience  18 \n",
      "\n",
      "Epoch  51 , training err  1.856 %, val err  2.79 %, patience  17 \n",
      "\n",
      "Epoch  52 , training err  1.826 %, val err  2.75 %, patience  20 \n",
      "\n",
      "Epoch  53 , training err  1.894 %, val err  2.93 %, patience  19 \n",
      "\n",
      "Epoch  54 , training err  1.848 %, val err  2.83 %, patience  18 \n",
      "\n",
      "Epoch  55 , training err  1.92 %, val err  2.95 %, patience  17 \n",
      "\n",
      "Epoch  56 , training err  1.91 %, val err  2.96 %, patience  16 \n",
      "\n",
      "Epoch  57 , training err  1.986 %, val err  2.82 %, patience  15 \n",
      "\n",
      "Epoch  58 , training err  1.978 %, val err  2.93 %, patience  14 \n",
      "\n",
      "Epoch  59 , training err  1.956 %, val err  2.81 %, patience  13 \n",
      "\n",
      "Epoch  60 , training err  1.75 %, val err  2.82 %, patience  12 \n",
      "\n",
      "Epoch  61 , training err  1.792 %, val err  2.91 %, patience  11 \n",
      "\n",
      "Epoch  62 , training err  1.824 %, val err  2.64 %, patience  20 \n",
      "\n",
      "Epoch  63 , training err  1.906 %, val err  3.0 %, patience  19 \n",
      "\n",
      "Epoch  64 , training err  1.998 %, val err  2.81 %, patience  18 \n",
      "\n",
      "Epoch  65 , training err  1.774 %, val err  2.75 %, patience  17 \n",
      "\n",
      "Epoch  66 , training err  1.896 %, val err  3.01 %, patience  16 \n",
      "\n",
      "Epoch  67 , training err  1.81 %, val err  2.93 %, patience  15 \n",
      "\n",
      "Epoch  68 , training err  1.694 %, val err  2.65 %, patience  14 \n",
      "\n",
      "Epoch  69 , training err  1.812 %, val err  3.03 %, patience  13 \n",
      "\n",
      "Epoch  70 , training err  1.718 %, val err  2.71 %, patience  12 \n",
      "\n",
      "Epoch  71 , training err  1.814 %, val err  2.84 %, patience  11 \n",
      "\n",
      "Epoch  72 , training err  1.73 %, val err  2.82 %, patience  10 \n",
      "\n",
      "Epoch  73 , training err  1.862 %, val err  3.0 %, patience  9 \n",
      "\n",
      "Epoch  74 , training err  1.81 %, val err  2.99 %, patience  8 \n",
      "\n",
      "Epoch  75 , training err  1.77 %, val err  2.88 %, patience  7 \n",
      "\n",
      "Epoch  76 , training err  1.784 %, val err  2.7 %, patience  6 \n",
      "\n",
      "Epoch  77 , training err  1.774 %, val err  2.8 %, patience  5 \n",
      "\n",
      "Epoch  78 , training err  1.758 %, val err  2.8 %, patience  4 \n",
      "\n",
      "Epoch  79 , training err  1.802 %, val err  2.83 %, patience  3 \n",
      "\n",
      "Epoch  80 , training err  1.742 %, val err  2.78 %, patience  2 \n",
      "\n",
      "Epoch  81 , training err  1.87 %, val err  2.81 %, patience  1 \n",
      "\n",
      "Epoch  82 , training err  1.738 %, val err  2.78 %, patience  0 \n",
      "\n",
      "Best val err  2.64 % at epoch  62  corresponding train err  1.824 %\n",
      "Epoch  0 , training err  7.368 %, val err  6.75 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  5.704 %, val err  5.33 %, patience  20 \n",
      "\n",
      "Epoch  2 , training err  4.806 %, val err  4.5 %, patience  20 \n",
      "\n",
      "Epoch  3 , training err  3.948 %, val err  4.0 %, patience  20 \n",
      "\n",
      "Epoch  4 , training err  3.536 %, val err  3.83 %, patience  20 \n",
      "\n",
      "Epoch  5 , training err  3.382 %, val err  3.75 %, patience  20 \n",
      "\n",
      "Epoch  6 , training err  3.068 %, val err  3.42 %, patience  20 \n",
      "\n",
      "Epoch  7 , training err  3.144 %, val err  3.68 %, patience  19 \n",
      "\n",
      "Epoch  8 , training err  2.874 %, val err  3.48 %, patience  18 \n",
      "\n",
      "Epoch  9 , training err  2.554 %, val err  3.33 %, patience  20 \n",
      "\n",
      "Epoch  10 , training err  2.44 %, val err  3.17 %, patience  20 \n",
      "\n",
      "Epoch  11 , training err  2.664 %, val err  3.36 %, patience  19 \n",
      "\n",
      "Epoch  12 , training err  2.438 %, val err  3.12 %, patience  20 \n",
      "\n",
      "Epoch  13 , training err  2.312 %, val err  3.06 %, patience  20 \n",
      "\n",
      "Epoch  14 , training err  2.27 %, val err  3.07 %, patience  19 \n",
      "\n",
      "Epoch  15 , training err  2.396 %, val err  3.32 %, patience  18 \n",
      "\n",
      "Epoch  16 , training err  2.052 %, val err  2.93 %, patience  20 \n",
      "\n",
      "Epoch  17 , training err  2.1 %, val err  2.95 %, patience  19 \n",
      "\n",
      "Epoch  18 , training err  2.094 %, val err  2.91 %, patience  20 \n",
      "\n",
      "Epoch  19 , training err  2.082 %, val err  2.93 %, patience  19 \n",
      "\n",
      "Epoch  20 , training err  2.106 %, val err  3.01 %, patience  18 \n",
      "\n",
      "Epoch  21 , training err  2.088 %, val err  2.87 %, patience  20 \n",
      "\n",
      "Epoch  22 , training err  2.266 %, val err  2.98 %, patience  19 \n",
      "\n",
      "Epoch  23 , training err  1.878 %, val err  2.73 %, patience  20 \n",
      "\n",
      "Epoch  24 , training err  1.946 %, val err  3.02 %, patience  19 \n",
      "\n",
      "Epoch  25 , training err  1.998 %, val err  2.92 %, patience  18 \n",
      "\n",
      "Epoch  26 , training err  2.12 %, val err  2.94 %, patience  17 \n",
      "\n",
      "Epoch  27 , training err  1.966 %, val err  2.9 %, patience  16 \n",
      "\n",
      "Epoch  28 , training err  1.976 %, val err  2.89 %, patience  15 \n",
      "\n",
      "Epoch  29 , training err  2.05 %, val err  2.85 %, patience  14 \n",
      "\n",
      "Epoch  30 , training err  1.812 %, val err  2.73 %, patience  13 \n",
      "\n",
      "Epoch  31 , training err  1.778 %, val err  2.85 %, patience  12 \n",
      "\n",
      "Epoch  32 , training err  2.024 %, val err  2.95 %, patience  11 \n",
      "\n",
      "Epoch  33 , training err  1.832 %, val err  2.76 %, patience  10 \n",
      "\n",
      "Epoch  34 , training err  1.78 %, val err  2.76 %, patience  9 \n",
      "\n",
      "Epoch  35 , training err  1.724 %, val err  2.72 %, patience  20 \n",
      "\n",
      "Epoch  36 , training err  1.868 %, val err  2.74 %, patience  19 \n",
      "\n",
      "Epoch  37 , training err  1.794 %, val err  2.78 %, patience  18 \n",
      "\n",
      "Epoch  38 , training err  2.072 %, val err  3.11 %, patience  17 \n",
      "\n",
      "Epoch  39 , training err  1.864 %, val err  2.89 %, patience  16 \n",
      "\n",
      "Epoch  40 , training err  1.936 %, val err  2.93 %, patience  15 \n",
      "\n",
      "Epoch  41 , training err  1.848 %, val err  2.66 %, patience  20 \n",
      "\n",
      "Epoch  42 , training err  1.688 %, val err  2.62 %, patience  20 \n",
      "\n",
      "Epoch  43 , training err  1.844 %, val err  2.73 %, patience  19 \n",
      "\n",
      "Epoch  44 , training err  1.782 %, val err  2.83 %, patience  18 \n",
      "\n",
      "Epoch  45 , training err  1.836 %, val err  2.81 %, patience  17 \n",
      "\n",
      "Epoch  46 , training err  1.742 %, val err  2.59 %, patience  20 \n",
      "\n",
      "Epoch  47 , training err  1.902 %, val err  2.91 %, patience  19 \n",
      "\n",
      "Epoch  48 , training err  1.784 %, val err  2.64 %, patience  18 \n",
      "\n",
      "Epoch  49 , training err  1.868 %, val err  2.72 %, patience  17 \n",
      "\n",
      "Epoch  50 , training err  1.756 %, val err  2.76 %, patience  16 \n",
      "\n",
      "Epoch  51 , training err  1.898 %, val err  2.88 %, patience  15 \n",
      "\n",
      "Epoch  52 , training err  1.732 %, val err  2.69 %, patience  14 \n",
      "\n",
      "Epoch  53 , training err  1.986 %, val err  2.83 %, patience  13 \n",
      "\n",
      "Epoch  54 , training err  1.922 %, val err  2.79 %, patience  12 \n",
      "\n",
      "Epoch  55 , training err  1.834 %, val err  2.72 %, patience  11 \n",
      "\n",
      "Epoch  56 , training err  1.592 %, val err  2.58 %, patience  20 \n",
      "\n",
      "Epoch  57 , training err  1.644 %, val err  2.64 %, patience  19 \n",
      "\n",
      "Epoch  58 , training err  1.662 %, val err  2.63 %, patience  18 \n",
      "\n",
      "Epoch  59 , training err  1.892 %, val err  2.83 %, patience  17 \n",
      "\n",
      "Epoch  60 , training err  1.718 %, val err  2.68 %, patience  16 \n",
      "\n",
      "Epoch  61 , training err  1.618 %, val err  2.59 %, patience  15 \n",
      "\n",
      "Epoch  62 , training err  1.862 %, val err  2.74 %, patience  14 \n",
      "\n",
      "Epoch  63 , training err  1.67 %, val err  2.61 %, patience  13 \n",
      "\n",
      "Epoch  64 , training err  1.674 %, val err  2.59 %, patience  12 \n",
      "\n",
      "Epoch  65 , training err  1.77 %, val err  2.73 %, patience  11 \n",
      "\n",
      "Epoch  66 , training err  1.808 %, val err  2.65 %, patience  10 \n",
      "\n",
      "Epoch  67 , training err  1.77 %, val err  2.68 %, patience  9 \n",
      "\n",
      "Epoch  68 , training err  1.81 %, val err  2.81 %, patience  8 \n",
      "\n",
      "Epoch  69 , training err  1.864 %, val err  2.89 %, patience  7 \n",
      "\n",
      "Epoch  70 , training err  1.738 %, val err  2.64 %, patience  6 \n",
      "\n",
      "Epoch  71 , training err  1.774 %, val err  2.92 %, patience  5 \n",
      "\n",
      "Epoch  72 , training err  1.634 %, val err  2.59 %, patience  4 \n",
      "\n",
      "Epoch  73 , training err  2.014 %, val err  3.02 %, patience  3 \n",
      "\n",
      "Epoch  74 , training err  1.698 %, val err  2.57 %, patience  20 \n",
      "\n",
      "Epoch  75 , training err  1.746 %, val err  2.75 %, patience  19 \n",
      "\n",
      "Epoch  76 , training err  1.82 %, val err  2.71 %, patience  18 \n",
      "\n",
      "Epoch  77 , training err  1.754 %, val err  2.82 %, patience  17 \n",
      "\n",
      "Epoch  78 , training err  1.622 %, val err  2.64 %, patience  16 \n",
      "\n",
      "Epoch  79 , training err  1.83 %, val err  2.68 %, patience  15 \n",
      "\n",
      "Epoch  80 , training err  1.728 %, val err  2.64 %, patience  14 \n",
      "\n",
      "Epoch  81 , training err  1.742 %, val err  2.72 %, patience  13 \n",
      "\n",
      "Epoch  82 , training err  1.828 %, val err  2.96 %, patience  12 \n",
      "\n",
      "Epoch  83 , training err  1.734 %, val err  2.67 %, patience  11 \n",
      "\n",
      "Epoch  84 , training err  1.644 %, val err  2.63 %, patience  10 \n",
      "\n",
      "Epoch  85 , training err  1.668 %, val err  2.58 %, patience  9 \n",
      "\n",
      "Epoch  86 , training err  1.584 %, val err  2.49 %, patience  20 \n",
      "\n",
      "Epoch  87 , training err  1.598 %, val err  2.55 %, patience  19 \n",
      "\n",
      "Epoch  88 , training err  1.596 %, val err  2.67 %, patience  18 \n",
      "\n",
      "Epoch  89 , training err  1.596 %, val err  2.53 %, patience  17 \n",
      "\n",
      "Epoch  90 , training err  1.696 %, val err  2.62 %, patience  16 \n",
      "\n",
      "Epoch  91 , training err  1.682 %, val err  2.76 %, patience  15 \n",
      "\n",
      "Epoch  92 , training err  1.666 %, val err  2.68 %, patience  14 \n",
      "\n",
      "Epoch  93 , training err  1.644 %, val err  2.54 %, patience  13 \n",
      "\n",
      "Epoch  94 , training err  1.524 %, val err  2.5 %, patience  12 \n",
      "\n",
      "Epoch  95 , training err  1.78 %, val err  2.65 %, patience  11 \n",
      "\n",
      "Epoch  96 , training err  1.722 %, val err  2.69 %, patience  10 \n",
      "\n",
      "Epoch  97 , training err  1.61 %, val err  2.66 %, patience  9 \n",
      "\n",
      "Epoch  98 , training err  1.664 %, val err  2.63 %, patience  8 \n",
      "\n",
      "Epoch  99 , training err  1.642 %, val err  2.64 %, patience  7 \n",
      "\n",
      "Epoch  100 , training err  1.786 %, val err  2.83 %, patience  6 \n",
      "\n",
      "Epoch  101 , training err  1.69 %, val err  2.74 %, patience  5 \n",
      "\n",
      "Epoch  102 , training err  1.702 %, val err  2.58 %, patience  4 \n",
      "\n",
      "Epoch  103 , training err  1.576 %, val err  2.53 %, patience  3 \n",
      "\n",
      "Epoch  104 , training err  1.842 %, val err  2.76 %, patience  2 \n",
      "\n",
      "Epoch  105 , training err  1.642 %, val err  2.67 %, patience  1 \n",
      "\n",
      "Epoch  106 , training err  1.656 %, val err  2.6 %, patience  0 \n",
      "\n",
      "Best val err  2.49 % at epoch  86  corresponding train err  1.584 %\n",
      "Epoch  0 , training err  7.464 %, val err  6.9 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  6.254 %, val err  5.88 %, patience  20 \n",
      "\n",
      "Epoch  2 , training err  5.564 %, val err  5.33 %, patience  20 \n",
      "\n",
      "Epoch  3 , training err  3.8 %, val err  3.9 %, patience  20 \n",
      "\n",
      "Epoch  4 , training err  3.634 %, val err  3.62 %, patience  20 \n",
      "\n",
      "Epoch  5 , training err  3.224 %, val err  3.42 %, patience  20 \n",
      "\n",
      "Epoch  6 , training err  2.872 %, val err  3.24 %, patience  20 \n",
      "\n",
      "Epoch  7 , training err  2.462 %, val err  2.93 %, patience  20 \n",
      "\n",
      "Epoch  8 , training err  2.452 %, val err  3.03 %, patience  19 \n",
      "\n",
      "Epoch  9 , training err  2.322 %, val err  2.86 %, patience  20 \n",
      "\n",
      "Epoch  10 , training err  2.482 %, val err  2.97 %, patience  19 \n",
      "\n",
      "Epoch  11 , training err  2.318 %, val err  2.88 %, patience  18 \n",
      "\n",
      "Epoch  12 , training err  1.942 %, val err  2.65 %, patience  20 \n",
      "\n",
      "Epoch  13 , training err  1.916 %, val err  2.66 %, patience  19 \n",
      "\n",
      "Epoch  14 , training err  1.928 %, val err  2.67 %, patience  18 \n",
      "\n",
      "Epoch  15 , training err  2.042 %, val err  2.73 %, patience  17 \n",
      "\n",
      "Epoch  16 , training err  1.738 %, val err  2.63 %, patience  20 \n",
      "\n",
      "Epoch  17 , training err  2.024 %, val err  2.78 %, patience  19 \n",
      "\n",
      "Epoch  18 , training err  1.77 %, val err  2.53 %, patience  20 \n",
      "\n",
      "Epoch  19 , training err  1.952 %, val err  2.87 %, patience  19 \n",
      "\n",
      "Epoch  20 , training err  1.658 %, val err  2.53 %, patience  18 \n",
      "\n",
      "Epoch  21 , training err  1.666 %, val err  2.48 %, patience  20 \n",
      "\n",
      "Epoch  22 , training err  1.67 %, val err  2.53 %, patience  19 \n",
      "\n",
      "Epoch  23 , training err  1.79 %, val err  2.61 %, patience  18 \n",
      "\n",
      "Epoch  24 , training err  1.698 %, val err  2.54 %, patience  17 \n",
      "\n",
      "Epoch  25 , training err  1.758 %, val err  2.59 %, patience  16 \n",
      "\n",
      "Epoch  26 , training err  1.562 %, val err  2.56 %, patience  15 \n",
      "\n",
      "Epoch  27 , training err  1.454 %, val err  2.47 %, patience  20 \n",
      "\n",
      "Epoch  28 , training err  1.796 %, val err  2.7 %, patience  19 \n",
      "\n",
      "Epoch  29 , training err  1.656 %, val err  2.61 %, patience  18 \n",
      "\n",
      "Epoch  30 , training err  1.486 %, val err  2.4 %, patience  20 \n",
      "\n",
      "Epoch  31 , training err  1.656 %, val err  2.63 %, patience  19 \n",
      "\n",
      "Epoch  32 , training err  1.68 %, val err  2.57 %, patience  18 \n",
      "\n",
      "Epoch  33 , training err  1.732 %, val err  2.45 %, patience  17 \n",
      "\n",
      "Epoch  34 , training err  1.386 %, val err  2.3 %, patience  20 \n",
      "\n",
      "Epoch  35 , training err  1.418 %, val err  2.36 %, patience  19 \n",
      "\n",
      "Epoch  36 , training err  1.528 %, val err  2.46 %, patience  18 \n",
      "\n",
      "Epoch  37 , training err  1.402 %, val err  2.49 %, patience  17 \n",
      "\n",
      "Epoch  38 , training err  1.474 %, val err  2.34 %, patience  16 \n",
      "\n",
      "Epoch  39 , training err  1.43 %, val err  2.25 %, patience  20 \n",
      "\n",
      "Epoch  40 , training err  1.394 %, val err  2.42 %, patience  19 \n",
      "\n",
      "Epoch  41 , training err  1.42 %, val err  2.31 %, patience  18 \n",
      "\n",
      "Epoch  42 , training err  1.652 %, val err  2.34 %, patience  17 \n",
      "\n",
      "Epoch  43 , training err  1.53 %, val err  2.47 %, patience  16 \n",
      "\n",
      "Epoch  44 , training err  1.478 %, val err  2.45 %, patience  15 \n",
      "\n",
      "Epoch  45 , training err  1.536 %, val err  2.43 %, patience  14 \n",
      "\n",
      "Epoch  46 , training err  1.524 %, val err  2.53 %, patience  13 \n",
      "\n",
      "Epoch  47 , training err  1.36 %, val err  2.37 %, patience  12 \n",
      "\n",
      "Epoch  48 , training err  1.582 %, val err  2.43 %, patience  11 \n",
      "\n",
      "Epoch  49 , training err  1.418 %, val err  2.31 %, patience  10 \n",
      "\n",
      "Epoch  50 , training err  1.376 %, val err  2.25 %, patience  9 \n",
      "\n",
      "Epoch  51 , training err  1.596 %, val err  2.42 %, patience  8 \n",
      "\n",
      "Epoch  52 , training err  1.498 %, val err  2.44 %, patience  7 \n",
      "\n",
      "Epoch  53 , training err  1.386 %, val err  2.37 %, patience  6 \n",
      "\n",
      "Epoch  54 , training err  1.392 %, val err  2.3 %, patience  5 \n",
      "\n",
      "Epoch  55 , training err  1.364 %, val err  2.29 %, patience  4 \n",
      "\n",
      "Epoch  56 , training err  1.484 %, val err  2.56 %, patience  3 \n",
      "\n",
      "Epoch  57 , training err  1.534 %, val err  2.43 %, patience  2 \n",
      "\n",
      "Epoch  58 , training err  1.406 %, val err  2.31 %, patience  1 \n",
      "\n",
      "Epoch  59 , training err  1.374 %, val err  2.36 %, patience  0 \n",
      "\n",
      "Best val err  2.25 % at epoch  39  corresponding train err  1.43 %\n",
      "Hidden layer  1 . Test error  65.63 %\n",
      "Hidden layer  2 . Test error  34.58 %\n",
      "Hidden layer  5 . Test error  10.22 %\n",
      "Hidden layer  15 . Test error  4.35 %\n",
      "Hidden layer  20 . Test error  4.56 %\n",
      "Hidden layer  30 . Test error  2.95 %\n",
      "Hidden layer  40 . Test error  2.77 %\n",
      "Hidden layer  50 . Test error  2.81 %\n",
      "Hidden layer  100 . Test error  2.46 %\n"
     ]
    }
   ],
   "source": [
    "middle = [1, 2, 5, 15, 20, 30, 40, 50, 100]\n",
    "for mid in middle:\n",
    "    bWs,tE,vE = train_neural_net(X_train, Y_train, X_val, Y_val, [784,mid,10], 0.1, 10, 20, 0.0001);\n",
    "    bestWs.append((bWs, mid));\n",
    "    train_errs.append(tE);\n",
    "    val_errs.append(vE);\n",
    "\n",
    "for WS, mid in bestWs:\n",
    "    print  'Hidden layer ', mid,  '. Test error ', meanBinaryError(X_test, WS, Y_test)*100, '%';\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ta nhận thấy độ lỗi trên tập train và validation ứng với l2_reg_level = 0.001 đều cao, và cao hơn so với các giá trị l2 khác. Điều này cho thấy mô hình này bị underfiting do giá trị l2 khá cao dẫn đến việc các giá trị Ws tương ứng không được \"dao động thoải mái\" và có xu hướng gần giá trị 0 để tối ưu hàm chi phí J do đó khó đạt được tới mô hình tối ưu.\n",
    "- Ngược lại với giá trị l2 = 0, thì mô hình này có độ lỗi trên tập train xuống rất thấp nhưng đồng thời độ lỗi trên tập validation ban đầu có xu hướng xuống nhưng sau lại tăng lên. Điều này cho thấy mô hình này bị overfiting do giá trị l2 quá thấp dẫn tới việc các giá trị Ws 'thoải mái di chuyển' và cố gắng fit tập train (gồm cả nhiễu) dẫn tới việc mô hình không được tổng quát.\n",
    "- Còn với giá trị l2 = 0.001 thì ta thấy độ lỗi trên tập train và tập validation đều có xu hướng đi xuống và có giá trị thấp. Mô hình này tương đối tốt nếu so với 2 mô hình còn lại do giá trị l2 được chọn khá cân bằng (không quá cao hay thấp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 , training err  9.082 %, val err  8.62 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  6.254 %, val err  5.85 %, patience  20 \n",
      "\n",
      "Epoch  2 , training err  4.692 %, val err  4.63 %, patience  20 \n",
      "\n",
      "Epoch  3 , training err  3.832 %, val err  3.98 %, patience  20 \n",
      "\n",
      "Epoch  4 , training err  3.674 %, val err  4.17 %, patience  19 \n",
      "\n",
      "Epoch  5 , training err  2.99 %, val err  3.65 %, patience  20 \n",
      "\n",
      "Epoch  6 , training err  3.24 %, val err  3.82 %, patience  19 \n",
      "\n",
      "Epoch  7 , training err  2.518 %, val err  3.17 %, patience  20 \n",
      "\n",
      "Epoch  8 , training err  2.308 %, val err  3.08 %, patience  20 \n",
      "\n",
      "Epoch  9 , training err  2.342 %, val err  3.28 %, patience  19 \n",
      "\n",
      "Epoch  10 , training err  2.2 %, val err  3.01 %, patience  20 \n",
      "\n",
      "Epoch  11 , training err  2.264 %, val err  3.09 %, patience  19 \n",
      "\n",
      "Epoch  12 , training err  1.862 %, val err  2.64 %, patience  20 \n",
      "\n",
      "Epoch  13 , training err  1.956 %, val err  2.78 %, patience  19 \n",
      "\n",
      "Epoch  14 , training err  1.942 %, val err  2.76 %, patience  18 \n",
      "\n",
      "Epoch  15 , training err  1.86 %, val err  2.78 %, patience  17 \n",
      "\n",
      "Epoch  16 , training err  1.642 %, val err  2.59 %, patience  20 \n",
      "\n",
      "Epoch  17 , training err  2.012 %, val err  2.96 %, patience  19 \n",
      "\n",
      "Epoch  18 , training err  1.648 %, val err  2.78 %, patience  18 \n",
      "\n",
      "Epoch  19 , training err  1.768 %, val err  2.72 %, patience  17 \n",
      "\n",
      "Epoch  20 , training err  1.526 %, val err  2.61 %, patience  16 \n",
      "\n",
      "Epoch  21 , training err  1.584 %, val err  2.69 %, patience  15 \n",
      "\n",
      "Epoch  22 , training err  1.808 %, val err  2.79 %, patience  14 \n",
      "\n",
      "Epoch  23 , training err  1.906 %, val err  2.82 %, patience  13 \n",
      "\n",
      "Epoch  24 , training err  1.552 %, val err  2.53 %, patience  20 \n",
      "\n",
      "Epoch  25 , training err  1.616 %, val err  2.9 %, patience  19 \n",
      "\n",
      "Epoch  26 , training err  2.414 %, val err  3.34 %, patience  18 \n",
      "\n",
      "Epoch  27 , training err  1.5 %, val err  2.52 %, patience  20 \n",
      "\n",
      "Epoch  28 , training err  1.538 %, val err  2.74 %, patience  19 \n",
      "\n",
      "Epoch  29 , training err  1.618 %, val err  2.74 %, patience  18 \n",
      "\n",
      "Epoch  30 , training err  1.43 %, val err  2.62 %, patience  17 \n",
      "\n",
      "Epoch  31 , training err  1.33 %, val err  2.66 %, patience  16 \n",
      "\n",
      "Epoch  32 , training err  1.434 %, val err  2.5 %, patience  20 \n",
      "\n",
      "Epoch  33 , training err  1.31 %, val err  2.6 %, patience  19 \n",
      "\n",
      "Epoch  34 , training err  1.396 %, val err  2.54 %, patience  18 \n",
      "\n",
      "Epoch  35 , training err  1.534 %, val err  2.62 %, patience  17 \n",
      "\n",
      "Epoch  36 , training err  1.72 %, val err  2.68 %, patience  16 \n",
      "\n",
      "Epoch  37 , training err  1.378 %, val err  2.42 %, patience  20 \n",
      "\n",
      "Epoch  38 , training err  1.316 %, val err  2.69 %, patience  19 \n",
      "\n",
      "Epoch  39 , training err  1.21 %, val err  2.49 %, patience  18 \n",
      "\n",
      "Epoch  40 , training err  1.64 %, val err  2.87 %, patience  17 \n",
      "\n",
      "Epoch  41 , training err  1.21 %, val err  2.55 %, patience  16 \n",
      "\n",
      "Epoch  42 , training err  1.224 %, val err  2.52 %, patience  15 \n",
      "\n",
      "Epoch  43 , training err  1.794 %, val err  3.02 %, patience  14 \n",
      "\n",
      "Epoch  44 , training err  1.51 %, val err  2.61 %, patience  13 \n",
      "\n",
      "Epoch  45 , training err  1.382 %, val err  2.61 %, patience  12 \n",
      "\n",
      "Epoch  46 , training err  1.448 %, val err  2.64 %, patience  11 \n",
      "\n",
      "Epoch  47 , training err  1.242 %, val err  2.57 %, patience  10 \n",
      "\n",
      "Epoch  48 , training err  1.252 %, val err  2.42 %, patience  9 \n",
      "\n",
      "Epoch  49 , training err  1.452 %, val err  2.74 %, patience  8 \n",
      "\n",
      "Epoch  50 , training err  1.378 %, val err  2.76 %, patience  7 \n",
      "\n",
      "Epoch  51 , training err  1.244 %, val err  2.61 %, patience  6 \n",
      "\n",
      "Epoch  52 , training err  1.282 %, val err  2.56 %, patience  5 \n",
      "\n",
      "Epoch  53 , training err  1.332 %, val err  2.8 %, patience  4 \n",
      "\n",
      "Epoch  54 , training err  1.366 %, val err  2.56 %, patience  3 \n",
      "\n",
      "Epoch  55 , training err  1.692 %, val err  2.84 %, patience  2 \n",
      "\n",
      "Epoch  56 , training err  1.378 %, val err  2.56 %, patience  1 \n",
      "\n",
      "Epoch  57 , training err  1.158 %, val err  2.43 %, patience  0 \n",
      "\n",
      "Best val err  2.42 % at epoch  37  corresponding train err  1.378 %\n",
      "Epoch  0 , training err  13.074 %, val err  11.97 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  7.36 %, val err  7.0 %, patience  20 \n",
      "\n",
      "Epoch  2 , training err  5.036 %, val err  4.96 %, patience  20 \n",
      "\n",
      "Epoch  3 , training err  3.998 %, val err  4.2 %, patience  20 \n",
      "\n",
      "Epoch  4 , training err  3.782 %, val err  4.34 %, patience  19 \n",
      "\n",
      "Epoch  5 , training err  4.264 %, val err  4.6 %, patience  18 \n",
      "\n",
      "Epoch  6 , training err  2.904 %, val err  3.69 %, patience  20 \n",
      "\n",
      "Epoch  7 , training err  2.628 %, val err  3.59 %, patience  20 \n",
      "\n",
      "Epoch  8 , training err  2.608 %, val err  3.47 %, patience  20 \n",
      "\n",
      "Epoch  9 , training err  2.8 %, val err  3.77 %, patience  19 \n",
      "\n",
      "Epoch  10 , training err  2.344 %, val err  3.44 %, patience  20 \n",
      "\n",
      "Epoch  11 , training err  2.762 %, val err  3.89 %, patience  19 \n",
      "\n",
      "Epoch  12 , training err  3.096 %, val err  4.08 %, patience  18 \n",
      "\n",
      "Epoch  13 , training err  2.15 %, val err  3.26 %, patience  20 \n",
      "\n",
      "Epoch  14 , training err  2.43 %, val err  3.38 %, patience  19 \n",
      "\n",
      "Epoch  15 , training err  2.16 %, val err  3.31 %, patience  18 \n",
      "\n",
      "Epoch  16 , training err  1.836 %, val err  3.2 %, patience  20 \n",
      "\n",
      "Epoch  17 , training err  1.696 %, val err  3.12 %, patience  20 \n",
      "\n",
      "Epoch  18 , training err  2.928 %, val err  3.9 %, patience  19 \n",
      "\n",
      "Epoch  19 , training err  1.562 %, val err  2.87 %, patience  20 \n",
      "\n",
      "Epoch  20 , training err  1.768 %, val err  2.96 %, patience  19 \n",
      "\n",
      "Epoch  21 , training err  1.57 %, val err  2.93 %, patience  18 \n",
      "\n",
      "Epoch  22 , training err  1.804 %, val err  3.02 %, patience  17 \n",
      "\n",
      "Epoch  23 , training err  1.674 %, val err  2.89 %, patience  16 \n",
      "\n",
      "Epoch  24 , training err  1.5 %, val err  2.86 %, patience  20 \n",
      "\n",
      "Epoch  25 , training err  1.448 %, val err  2.93 %, patience  19 \n",
      "\n",
      "Epoch  26 , training err  1.628 %, val err  2.92 %, patience  18 \n",
      "\n",
      "Epoch  27 , training err  1.646 %, val err  2.98 %, patience  17 \n",
      "\n",
      "Epoch  28 , training err  2.08 %, val err  3.35 %, patience  16 \n",
      "\n",
      "Epoch  29 , training err  1.246 %, val err  2.66 %, patience  20 \n",
      "\n",
      "Epoch  30 , training err  3.202 %, val err  3.98 %, patience  19 \n",
      "\n",
      "Epoch  31 , training err  1.506 %, val err  2.99 %, patience  18 \n",
      "\n",
      "Epoch  32 , training err  1.574 %, val err  2.98 %, patience  17 \n",
      "\n",
      "Epoch  33 , training err  1.266 %, val err  2.88 %, patience  16 \n",
      "\n",
      "Epoch  34 , training err  1.354 %, val err  2.9 %, patience  15 \n",
      "\n",
      "Epoch  35 , training err  1.388 %, val err  2.95 %, patience  14 \n",
      "\n",
      "Epoch  36 , training err  1.566 %, val err  3.1 %, patience  13 \n",
      "\n",
      "Epoch  37 , training err  1.416 %, val err  2.86 %, patience  12 \n",
      "\n",
      "Epoch  38 , training err  1.2 %, val err  2.7 %, patience  11 \n",
      "\n",
      "Epoch  39 , training err  1.632 %, val err  3.06 %, patience  10 \n",
      "\n",
      "Epoch  40 , training err  1.676 %, val err  3.35 %, patience  9 \n",
      "\n",
      "Epoch  41 , training err  2.194 %, val err  3.32 %, patience  8 \n",
      "\n",
      "Epoch  42 , training err  1.638 %, val err  3.15 %, patience  7 \n",
      "\n",
      "Epoch  43 , training err  1.706 %, val err  3.13 %, patience  6 \n",
      "\n",
      "Epoch  44 , training err  1.322 %, val err  2.83 %, patience  5 \n",
      "\n",
      "Epoch  45 , training err  1.552 %, val err  2.96 %, patience  4 \n",
      "\n",
      "Epoch  46 , training err  1.502 %, val err  3.09 %, patience  3 \n",
      "\n",
      "Epoch  47 , training err  1.326 %, val err  2.87 %, patience  2 \n",
      "\n",
      "Epoch  48 , training err  2.068 %, val err  3.33 %, patience  1 \n",
      "\n",
      "Epoch  49 , training err  1.432 %, val err  2.88 %, patience  0 \n",
      "\n",
      "Best val err  2.66 % at epoch  29  corresponding train err  1.246 %\n",
      "Epoch  0 , training err  90.282 %, val err  90.17 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  55.342 %, val err  55.68 %, patience  20 \n",
      "\n",
      "Epoch  2 , training err  28.786 %, val err  27.36 %, patience  20 \n",
      "\n",
      "Epoch  3 , training err  11.614 %, val err  11.19 %, patience  20 \n",
      "\n",
      "Epoch  4 , training err  9.402 %, val err  8.9 %, patience  20 \n",
      "\n",
      "Epoch  5 , training err  6.632 %, val err  6.68 %, patience  20 \n",
      "\n",
      "Epoch  6 , training err  6.278 %, val err  6.41 %, patience  20 \n",
      "\n",
      "Epoch  7 , training err  6.122 %, val err  6.31 %, patience  20 \n",
      "\n",
      "Epoch  8 , training err  4.654 %, val err  5.43 %, patience  20 \n",
      "\n",
      "Epoch  9 , training err  6.188 %, val err  6.73 %, patience  19 \n",
      "\n",
      "Epoch  10 , training err  4.122 %, val err  4.63 %, patience  20 \n",
      "\n",
      "Epoch  11 , training err  3.894 %, val err  4.33 %, patience  20 \n",
      "\n",
      "Epoch  12 , training err  4.126 %, val err  4.6 %, patience  19 \n",
      "\n",
      "Epoch  13 , training err  3.14 %, val err  3.91 %, patience  20 \n",
      "\n",
      "Epoch  14 , training err  3.29 %, val err  3.93 %, patience  19 \n",
      "\n",
      "Epoch  15 , training err  3.704 %, val err  4.38 %, patience  18 \n",
      "\n",
      "Epoch  16 , training err  3.206 %, val err  4.17 %, patience  17 \n",
      "\n",
      "Epoch  17 , training err  2.982 %, val err  3.83 %, patience  20 \n",
      "\n",
      "Epoch  18 , training err  2.508 %, val err  3.74 %, patience  20 \n",
      "\n",
      "Epoch  19 , training err  2.082 %, val err  3.31 %, patience  20 \n",
      "\n",
      "Epoch  20 , training err  3.126 %, val err  4.07 %, patience  19 \n",
      "\n",
      "Epoch  21 , training err  2.588 %, val err  3.78 %, patience  18 \n",
      "\n",
      "Epoch  22 , training err  3.244 %, val err  3.95 %, patience  17 \n",
      "\n",
      "Epoch  23 , training err  3.172 %, val err  3.89 %, patience  16 \n",
      "\n",
      "Epoch  24 , training err  2.596 %, val err  3.51 %, patience  15 \n",
      "\n",
      "Epoch  25 , training err  2.298 %, val err  3.51 %, patience  14 \n",
      "\n",
      "Epoch  26 , training err  2.736 %, val err  3.88 %, patience  13 \n",
      "\n",
      "Epoch  27 , training err  3.596 %, val err  4.73 %, patience  12 \n",
      "\n",
      "Epoch  28 , training err  2.01 %, val err  3.2 %, patience  20 \n",
      "\n",
      "Epoch  29 , training err  1.926 %, val err  3.31 %, patience  19 \n",
      "\n",
      "Epoch  30 , training err  1.778 %, val err  3.13 %, patience  20 \n",
      "\n",
      "Epoch  31 , training err  1.882 %, val err  3.16 %, patience  19 \n",
      "\n",
      "Epoch  32 , training err  1.736 %, val err  3.08 %, patience  20 \n",
      "\n",
      "Epoch  33 , training err  1.544 %, val err  2.68 %, patience  20 \n",
      "\n",
      "Epoch  34 , training err  1.632 %, val err  3.0 %, patience  19 \n",
      "\n",
      "Epoch  35 , training err  2.298 %, val err  3.43 %, patience  18 \n",
      "\n",
      "Epoch  36 , training err  2.22 %, val err  3.46 %, patience  17 \n",
      "\n",
      "Epoch  37 , training err  1.684 %, val err  2.72 %, patience  16 \n",
      "\n",
      "Epoch  38 , training err  3.654 %, val err  4.64 %, patience  15 \n",
      "\n",
      "Epoch  39 , training err  2.174 %, val err  3.28 %, patience  14 \n",
      "\n",
      "Epoch  40 , training err  2.612 %, val err  3.69 %, patience  13 \n",
      "\n",
      "Epoch  41 , training err  2.18 %, val err  3.42 %, patience  12 \n",
      "\n",
      "Epoch  42 , training err  1.636 %, val err  2.9 %, patience  11 \n",
      "\n",
      "Epoch  43 , training err  2.202 %, val err  3.33 %, patience  10 \n",
      "\n",
      "Epoch  44 , training err  1.632 %, val err  2.93 %, patience  9 \n",
      "\n",
      "Epoch  45 , training err  1.608 %, val err  3.02 %, patience  8 \n",
      "\n",
      "Epoch  46 , training err  1.38 %, val err  2.97 %, patience  7 \n",
      "\n",
      "Epoch  47 , training err  1.234 %, val err  2.67 %, patience  20 \n",
      "\n",
      "Epoch  48 , training err  1.794 %, val err  3.19 %, patience  19 \n",
      "\n",
      "Epoch  49 , training err  1.568 %, val err  2.79 %, patience  18 \n",
      "\n",
      "Epoch  50 , training err  1.624 %, val err  2.95 %, patience  17 \n",
      "\n",
      "Epoch  51 , training err  1.854 %, val err  3.08 %, patience  16 \n",
      "\n",
      "Epoch  52 , training err  2.042 %, val err  3.25 %, patience  15 \n",
      "\n",
      "Epoch  53 , training err  1.484 %, val err  2.76 %, patience  14 \n",
      "\n",
      "Epoch  54 , training err  3.214 %, val err  4.53 %, patience  13 \n",
      "\n",
      "Epoch  55 , training err  1.396 %, val err  2.92 %, patience  12 \n",
      "\n",
      "Epoch  56 , training err  1.724 %, val err  2.86 %, patience  11 \n",
      "\n",
      "Epoch  57 , training err  2.438 %, val err  3.44 %, patience  10 \n",
      "\n",
      "Epoch  58 , training err  1.698 %, val err  3.09 %, patience  9 \n",
      "\n",
      "Epoch  59 , training err  1.926 %, val err  3.02 %, patience  8 \n",
      "\n",
      "Epoch  60 , training err  1.552 %, val err  2.98 %, patience  7 \n",
      "\n",
      "Epoch  61 , training err  1.816 %, val err  3.3 %, patience  6 \n",
      "\n",
      "Epoch  62 , training err  1.702 %, val err  2.96 %, patience  5 \n",
      "\n",
      "Epoch  63 , training err  1.786 %, val err  3.07 %, patience  4 \n",
      "\n",
      "Epoch  64 , training err  2.286 %, val err  3.33 %, patience  3 \n",
      "\n",
      "Epoch  65 , training err  1.492 %, val err  2.68 %, patience  2 \n",
      "\n",
      "Epoch  66 , training err  1.532 %, val err  2.78 %, patience  1 \n",
      "\n",
      "Epoch  67 , training err  1.494 %, val err  2.8 %, patience  0 \n",
      "\n",
      "Best val err  2.67 % at epoch  47  corresponding train err  1.234 %\n",
      "1\n",
      ". Test error  65.63 %\n",
      "2\n",
      ". Test error  34.58 %\n",
      "5\n",
      ". Test error  10.22 %\n",
      "15\n",
      ". Test error  4.35 %\n",
      "20\n",
      ". Test error  4.56 %\n",
      "30\n",
      ". Test error  2.95 %\n",
      "40\n",
      ". Test error  2.77 %\n",
      "50\n",
      ". Test error  2.81 %\n",
      "100\n",
      ". Test error  2.46 %\n",
      "[784, 50, 30, 10]\n",
      ". Test error  2.63 %\n",
      "[784, 50, 30, 20, 10]\n",
      ". Test error  2.78 %\n",
      "[784, 50, 30, 20, 20, 10]\n",
      ". Test error  2.64 %\n"
     ]
    }
   ],
   "source": [
    "layer = [[784, 50, 30, 10], [784, 50, 30, 20, 10], [784, 50, 30, 20, 20, 10]]\n",
    "for ll in layer:\n",
    "    bWs,tE,vE = train_neural_net(X_train, Y_train, X_val, Y_val, ll, 0.1, 10, 20, 0.0001);\n",
    "    bestWs.append((bWs, ll));\n",
    "    train_errs.append(tE);\n",
    "    val_errs.append(vE);\n",
    "\n",
    "for WS, ll in bestWs:\n",
    "    print ll \n",
    "    print  '. Test error ', meanBinaryError(X_test, WS, Y_test)*100, '%';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 , training err  8.524 %, val err  8.02 %, patience  20 \n",
      "\n",
      "Epoch  1 , training err  6.382 %, val err  5.9 %, patience  20 \n",
      "\n",
      "Epoch  2 , training err  4.852 %, val err  4.58 %, patience  20 \n",
      "\n",
      "Epoch  3 , training err  4.266 %, val err  3.97 %, patience  20 \n",
      "\n",
      "Epoch  4 , training err  4.536 %, val err  4.54 %, patience  19 \n",
      "\n",
      "Epoch  5 , training err  3.284 %, val err  3.46 %, patience  20 \n",
      "\n",
      "Epoch  6 , training err  4.018 %, val err  3.97 %, patience  19 \n",
      "\n",
      "Epoch  7 , training err  2.768 %, val err  3.18 %, patience  20 \n",
      "\n",
      "Epoch  8 , training err  2.854 %, val err  3.22 %, patience  19 \n",
      "\n",
      "Epoch  9 , training err  2.24 %, val err  2.73 %, patience  20 \n",
      "\n",
      "Epoch  10 , training err  2.466 %, val err  2.93 %, patience  19 \n",
      "\n",
      "Epoch  11 , training err  2.402 %, val err  2.97 %, patience  18 \n",
      "\n",
      "Epoch  12 , training err  2.586 %, val err  3.09 %, patience  17 \n",
      "\n",
      "Epoch  13 , training err  2.074 %, val err  2.67 %, patience  20 \n",
      "\n",
      "Epoch  14 , training err  2.122 %, val err  2.72 %, patience  19 \n",
      "\n",
      "Epoch  15 , training err  2.186 %, val err  2.88 %, patience  18 \n",
      "\n",
      "Epoch  16 , training err  2.508 %, val err  2.95 %, patience  17 \n",
      "\n",
      "Epoch  17 , training err  2.162 %, val err  2.79 %, patience  16 \n",
      "\n",
      "Epoch  18 , training err  2.0 %, val err  2.78 %, patience  15 \n",
      "\n",
      "Epoch  19 , training err  1.832 %, val err  2.53 %, patience  20 \n",
      "\n",
      "Epoch  20 , training err  2.36 %, val err  3.16 %, patience  19 \n",
      "\n",
      "Epoch  21 , training err  1.802 %, val err  2.54 %, patience  18 \n",
      "\n",
      "Epoch  22 , training err  1.728 %, val err  2.55 %, patience  17 \n",
      "\n",
      "Epoch  23 , training err  1.846 %, val err  2.65 %, patience  16 \n",
      "\n",
      "Epoch  24 , training err  2.078 %, val err  3.09 %, patience  15 \n",
      "\n",
      "Epoch  25 , training err  1.922 %, val err  2.75 %, patience  14 \n",
      "\n",
      "Epoch  26 , training err  1.586 %, val err  2.33 %, patience  20 \n",
      "\n",
      "Epoch  27 , training err  2.462 %, val err  3.13 %, patience  19 \n",
      "\n",
      "Epoch  28 , training err  1.982 %, val err  2.95 %, patience  18 \n",
      "\n",
      "Epoch  29 , training err  1.64 %, val err  2.33 %, patience  17 \n",
      "\n",
      "Epoch  30 , training err  1.74 %, val err  2.51 %, patience  16 \n",
      "\n",
      "Epoch  31 , training err  1.628 %, val err  2.46 %, patience  15 \n",
      "\n",
      "Epoch  32 , training err  1.99 %, val err  2.79 %, patience  14 \n",
      "\n",
      "Epoch  33 , training err  1.406 %, val err  2.35 %, patience  13 \n",
      "\n",
      "Epoch  34 , training err  1.434 %, val err  2.28 %, patience  20 \n",
      "\n",
      "Epoch  35 , training err  2.078 %, val err  2.84 %, patience  19 \n",
      "\n",
      "Epoch  36 , training err  1.63 %, val err  2.39 %, patience  18 \n",
      "\n",
      "Epoch  37 , training err  1.742 %, val err  2.5 %, patience  17 \n",
      "\n",
      "Epoch  38 , training err  1.498 %, val err  2.36 %, patience  16 \n",
      "\n",
      "Epoch  39 , training err  1.422 %, val err  2.25 %, patience  20 \n",
      "\n",
      "Epoch  40 , training err  3.03 %, val err  3.63 %, patience  19 \n",
      "\n",
      "Epoch  41 , training err  1.95 %, val err  2.84 %, patience  18 \n",
      "\n",
      "Epoch  42 , training err  1.768 %, val err  2.67 %, patience  17 \n",
      "\n",
      "Epoch  43 , training err  1.776 %, val err  2.65 %, patience  16 \n",
      "\n",
      "Epoch  44 , training err  1.512 %, val err  2.6 %, patience  15 \n",
      "\n",
      "Epoch  45 , training err  1.348 %, val err  2.14 %, patience  20 \n",
      "\n",
      "Epoch  46 , training err  1.418 %, val err  2.24 %, patience  19 \n",
      "\n",
      "Epoch  47 , training err  1.938 %, val err  2.73 %, patience  18 \n",
      "\n",
      "Epoch  48 , training err  1.578 %, val err  2.54 %, patience  17 \n",
      "\n",
      "Epoch  49 , training err  1.43 %, val err  2.6 %, patience  16 \n",
      "\n",
      "Epoch  50 , training err  1.258 %, val err  2.29 %, patience  15 \n",
      "\n",
      "Epoch  51 , training err  1.612 %, val err  2.6 %, patience  14 \n",
      "\n",
      "Epoch  52 , training err  1.498 %, val err  2.45 %, patience  13 \n",
      "\n",
      "Epoch  53 , training err  1.83 %, val err  2.59 %, patience  12 \n",
      "\n",
      "Epoch  54 , training err  1.286 %, val err  2.04 %, patience  20 \n",
      "\n",
      "Epoch  55 , training err  1.372 %, val err  2.29 %, patience  19 \n",
      "\n",
      "Epoch  56 , training err  1.428 %, val err  2.22 %, patience  18 \n",
      "\n",
      "Epoch  57 , training err  2.008 %, val err  2.8 %, patience  17 \n",
      "\n",
      "Epoch  58 , training err  1.348 %, val err  2.18 %, patience  16 \n",
      "\n",
      "Epoch  59 , training err  1.448 %, val err  2.42 %, patience  15 \n",
      "\n",
      "Epoch  60 , training err  2.098 %, val err  2.94 %, patience  14 \n",
      "\n",
      "Epoch  61 , training err  1.26 %, val err  2.19 %, patience  13 \n",
      "\n",
      "Epoch  62 , training err  1.276 %, val err  2.19 %, patience  12 \n",
      "\n",
      "Epoch  63 , training err  1.356 %, val err  2.3 %, patience  11 \n",
      "\n",
      "Epoch  64 , training err  1.35 %, val err  2.34 %, patience  10 \n",
      "\n",
      "Epoch  65 , training err  1.364 %, val err  2.34 %, patience  9 \n",
      "\n",
      "Epoch  66 , training err  1.51 %, val err  2.4 %, patience  8 \n",
      "\n",
      "Epoch  67 , training err  1.41 %, val err  2.21 %, patience  7 \n",
      "\n",
      "Epoch  68 , training err  1.678 %, val err  2.52 %, patience  6 \n",
      "\n",
      "Epoch  69 , training err  1.522 %, val err  2.43 %, patience  5 \n",
      "\n",
      "Epoch  70 , training err  1.434 %, val err  2.57 %, patience  4 \n",
      "\n",
      "Epoch  71 , training err  1.682 %, val err  2.49 %, patience  3 \n",
      "\n",
      "Epoch  72 , training err  1.442 %, val err  2.26 %, patience  2 \n",
      "\n",
      "Epoch  73 , training err  1.322 %, val err  2.35 %, patience  1 \n",
      "\n",
      "Epoch  74 , training err  1.792 %, val err  2.73 %, patience  0 \n",
      "\n",
      "Best val err  2.04 % at epoch  54  corresponding train err  1.286 %\n",
      "Hidden layer  100 . Test error  2.34 %\n"
     ]
    }
   ],
   "source": [
    "bWs,tE,vE = train_neural_net(X_train, Y_train, X_val, Y_val, [784,200,10], 0.1, 10, 20, 0.0001);\n",
    "print  'Hidden layer ', mid,  '. Test error ', meanBinaryError(X_test, bWs, Y_test)*100, '%';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
